2026-02-13 03:25:27,273 | INFO | Logging to /algo/NetOptimization/outputs/VBP/MNv2_TP/global_lrv1/kr_0.7/vbp_imagenet.log
2026-02-13 03:25:27,273 | INFO | ============================================================
2026-02-13 03:25:27,273 | INFO | VBP ImageNet Reproduction Script
2026-02-13 03:25:27,273 | INFO | ============================================================
2026-02-13 03:25:27,273 | INFO |   model_type: cnn
2026-02-13 03:25:27,273 | INFO |   model_name: /algo/NetOptimization/outputs/VBP/MNv2_TP/mobilenet_v2_weights.pth
2026-02-13 03:25:27,273 | INFO |   cnn_arch: mobilenet_v2
2026-02-13 03:25:27,273 | INFO |   pretrained: True
2026-02-13 03:25:27,274 | INFO |   interior_only: True
2026-02-13 03:25:27,274 | INFO |   data_path: /algo/NetOptimization/outputs/VBP/
2026-02-13 03:25:27,274 | INFO |   train_batch_size: 64
2026-02-13 03:25:27,274 | INFO |   val_batch_size: 128
2026-02-13 03:25:27,274 | INFO |   num_workers: 4
2026-02-13 03:25:27,274 | INFO |   max_batches: 200
2026-02-13 03:25:27,274 | INFO |   keep_ratio: 0.7
2026-02-13 03:25:27,274 | INFO |   global_pruning: True
2026-02-13 03:25:27,274 | INFO |   max_pruning_ratio: 1.0
2026-02-13 03:25:27,274 | INFO |   norm_per_layer: False
2026-02-13 03:25:27,274 | INFO |   no_compensation: False
2026-02-13 03:25:27,274 | INFO |   no_recalib: False
2026-02-13 03:25:27,274 | INFO |   criterion: variance
2026-02-13 03:25:27,274 | INFO |   epochs_ft: 10
2026-02-13 03:25:27,274 | INFO |   lr_ft: 0.01
2026-02-13 03:25:27,274 | INFO |   opt_ft: sgd
2026-02-13 03:25:27,274 | INFO |   momentum_ft: 0.9
2026-02-13 03:25:27,274 | INFO |   wd_ft: 4e-05
2026-02-13 03:25:27,274 | INFO |   use_kd: True
2026-02-13 03:25:27,274 | INFO |   kd_alpha: 0.7
2026-02-13 03:25:27,274 | INFO |   kd_T: 2.0
2026-02-13 03:25:27,274 | INFO |   pat: False
2026-02-13 03:25:27,274 | INFO |   pat_steps: 5
2026-02-13 03:25:27,274 | INFO |   pat_epochs_per_step: 3
2026-02-13 03:25:27,274 | INFO |   var_loss_weight: 0.0
2026-02-13 03:25:27,274 | INFO |   sparse_mode: none
2026-02-13 03:25:27,274 | INFO |   epochs_sparse: 5
2026-02-13 03:25:27,274 | INFO |   lr_sparse: 0.0001
2026-02-13 03:25:27,275 | INFO |   l1_lambda: 0.0001
2026-02-13 03:25:27,275 | INFO |   gmp_target_sparsity: 0.5
2026-02-13 03:25:27,275 | INFO |   disable_ddp: False
2026-02-13 03:25:27,275 | INFO |   local_rank: 0
2026-02-13 03:25:27,275 | INFO |   save_dir: /algo/NetOptimization/outputs/VBP/MNv2_TP/global_lrv1/kr_0.7
2026-02-13 03:25:27,275 | INFO |   rank: 0
2026-02-13 03:25:27,275 | INFO |   world_size: 2
2026-02-13 03:25:27,275 | INFO | Loading ImageNet dataset...
2026-02-13 03:25:27,275 | INFO | Using cached sample lists for fast loading
2026-02-13 03:25:27,614 | INFO | Train samples: 1281167, Val samples: 50000
2026-02-13 03:25:29,351 | INFO | Loaded mobilenet_v2 (pretrained=True)
2026-02-13 03:25:30,661 | INFO | Baseline: 0.32G MACs, 3.50M params
2026-02-13 03:25:30,662 | INFO | Evaluating original model...
2026-02-13 03:26:37,980 | INFO | Original accuracy: 0.7187, loss: 1.1474
2026-02-13 03:26:38,008 | INFO | Created teacher model for knowledge distillation
2026-02-13 03:26:38,008 | INFO | PAT: 1 steps, per_step_keep=0.7000, epochs_per_step=0, target_keep=0.7, criterion=variance
2026-02-13 03:26:38,008 | INFO | 
============================================================
2026-02-13 03:26:38,008 | INFO | PAT Step 1/1
2026-02-13 03:26:38,008 | INFO | ============================================================
2026-02-13 03:26:38,030 | INFO | Auto-detected 35 CNN target layers for stats
2026-02-13 03:26:38,030 | INFO | Collecting activation variance statistics...
2026-02-13 03:26:54,483 | INFO | Statistics collected for 35 layers
2026-02-13 03:26:54,484 | INFO |   Conv2d: mean_var=0.027768
2026-02-13 03:26:54,484 | INFO |   Conv2d: mean_var=0.381319
2026-02-13 03:26:54,484 | INFO |   Conv2d: mean_var=0.045561
2026-02-13 03:26:54,485 | INFO |   Conv2d: mean_var=0.290696
2026-02-13 03:26:54,485 | INFO |   Conv2d: mean_var=0.015321
2026-02-13 03:26:54,632 | INFO | Variance â€” entropy=0.8413, cv=2.1458, gini=0.8130
2026-02-13 03:26:54,934 | INFO | Pruning: per_step_prune=0.3000
2026-02-13 03:26:55,161 | INFO | Pruning complete (criterion=VBP, compensation=on)
2026-02-13 03:26:55,161 | INFO | Recalibrating BN running stats...
2026-02-13 03:26:55,946 | INFO | BN recalib [1/100]
2026-02-13 03:26:56,169 | INFO | BN recalib [6/100]
2026-02-13 03:26:56,662 | INFO | BN recalib [11/100]
2026-02-13 03:26:57,185 | INFO | BN recalib [16/100]
2026-02-13 03:26:57,646 | INFO | BN recalib [21/100]
2026-02-13 03:26:58,085 | INFO | BN recalib [26/100]
2026-02-13 03:26:58,364 | INFO | BN recalib [31/100]
2026-02-13 03:26:58,687 | INFO | BN recalib [36/100]
2026-02-13 03:26:59,119 | INFO | BN recalib [41/100]
2026-02-13 03:26:59,527 | INFO | BN recalib [46/100]
2026-02-13 03:26:59,806 | INFO | BN recalib [51/100]
2026-02-13 03:27:00,085 | INFO | BN recalib [56/100]
2026-02-13 03:27:00,525 | INFO | BN recalib [61/100]
2026-02-13 03:27:00,948 | INFO | BN recalib [66/100]
2026-02-13 03:27:01,259 | INFO | BN recalib [71/100]
2026-02-13 03:27:01,529 | INFO | BN recalib [76/100]
2026-02-13 03:27:01,897 | INFO | BN recalib [81/100]
2026-02-13 03:27:02,362 | INFO | BN recalib [86/100]
2026-02-13 03:27:02,656 | INFO | BN recalib [91/100]
2026-02-13 03:27:02,935 | INFO | BN recalib [96/100]
2026-02-13 03:27:03,250 | INFO | BN recalib [100/100]
2026-02-13 03:27:03,613 | INFO | BN recalibration done (100 batches)
2026-02-13 03:28:10,882 | INFO | Step 1 retention: acc=0.0135, loss=7.4088
2026-02-13 03:28:10,882 | INFO |   cumulative_keep=0.7000, MACs=0.24G, params=2.73M
2026-02-13 03:28:10,883 | INFO | 
Post-prune fine-tuning for 10 epochs (sgd, lr=0.01, wd=4e-05)...
2026-02-13 03:28:12,025 | INFO | FT 1 [1/10009] loss=9.5865
2026-02-13 03:29:00,473 | INFO | FT 1 [501/10009] loss=4.3699
2026-02-13 03:29:47,668 | INFO | FT 1 [1001/10009] loss=3.9021
2026-02-13 03:30:34,411 | INFO | FT 1 [1501/10009] loss=3.6435
2026-02-13 03:31:21,256 | INFO | FT 1 [2001/10009] loss=3.4838
2026-02-13 03:32:07,908 | INFO | FT 1 [2501/10009] loss=3.3674
2026-02-13 03:32:54,370 | INFO | FT 1 [3001/10009] loss=3.2744
2026-02-13 03:33:40,970 | INFO | FT 1 [3501/10009] loss=3.1993
2026-02-13 03:34:28,192 | INFO | FT 1 [4001/10009] loss=3.1339
2026-02-13 03:35:15,010 | INFO | FT 1 [4501/10009] loss=3.0819
2026-02-13 03:36:01,623 | INFO | FT 1 [5001/10009] loss=3.0355
2026-02-13 03:36:48,118 | INFO | FT 1 [5501/10009] loss=2.9928
2026-02-13 03:37:34,591 | INFO | FT 1 [6001/10009] loss=2.9553
2026-02-13 03:38:21,039 | INFO | FT 1 [6501/10009] loss=2.9204
2026-02-13 03:39:07,586 | INFO | FT 1 [7001/10009] loss=2.8894
2026-02-13 03:39:54,097 | INFO | FT 1 [7501/10009] loss=2.8610
2026-02-13 03:40:40,521 | INFO | FT 1 [8001/10009] loss=2.8344
2026-02-13 03:41:26,981 | INFO | FT 1 [8501/10009] loss=2.8100
2026-02-13 03:42:13,282 | INFO | FT 1 [9001/10009] loss=2.7873
2026-02-13 03:42:59,711 | INFO | FT 1 [9501/10009] loss=2.7656
2026-02-13 03:43:45,889 | INFO | FT 1 [10001/10009] loss=2.7454
2026-02-13 03:43:46,648 | INFO | FT 1 [10009/10009] loss=2.7450
2026-02-13 03:44:53,700 | INFO | FT ep 1/10: train_loss=2.7450, val_acc=0.5430
2026-02-13 03:44:53,756 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/MNv2_TP/global_lrv1/kr_0.7/vbp_best.pth
2026-02-13 03:44:54,785 | INFO | FT 2 [1/10009] loss=2.1899
2026-02-13 03:45:42,918 | INFO | FT 2 [501/10009] loss=2.3167
2026-02-13 03:46:30,918 | INFO | FT 2 [1001/10009] loss=2.3133
2026-02-13 03:47:18,626 | INFO | FT 2 [1501/10009] loss=2.3113
2026-02-13 03:48:05,991 | INFO | FT 2 [2001/10009] loss=2.3019
2026-02-13 03:48:53,499 | INFO | FT 2 [2501/10009] loss=2.2955
2026-02-13 03:49:40,608 | INFO | FT 2 [3001/10009] loss=2.2893
2026-02-13 03:50:27,752 | INFO | FT 2 [3501/10009] loss=2.2833
2026-02-13 03:51:14,848 | INFO | FT 2 [4001/10009] loss=2.2776
2026-02-13 03:52:01,744 | INFO | FT 2 [4501/10009] loss=2.2713
2026-02-13 03:52:48,766 | INFO | FT 2 [5001/10009] loss=2.2686
2026-02-13 03:53:35,746 | INFO | FT 2 [5501/10009] loss=2.2632
2026-02-13 03:54:22,674 | INFO | FT 2 [6001/10009] loss=2.2569
2026-02-13 03:55:09,891 | INFO | FT 2 [6501/10009] loss=2.2523
2026-02-13 03:55:56,801 | INFO | FT 2 [7001/10009] loss=2.2478
2026-02-13 03:56:43,471 | INFO | FT 2 [7501/10009] loss=2.2432
2026-02-13 03:57:30,118 | INFO | FT 2 [8001/10009] loss=2.2390
2026-02-13 03:58:16,908 | INFO | FT 2 [8501/10009] loss=2.2339
2026-02-13 03:59:03,653 | INFO | FT 2 [9001/10009] loss=2.2295
2026-02-13 03:59:51,407 | INFO | FT 2 [9501/10009] loss=2.2248
2026-02-13 04:00:37,919 | INFO | FT 2 [10001/10009] loss=2.2195
2026-02-13 04:00:38,686 | INFO | FT 2 [10009/10009] loss=2.2194
2026-02-13 04:01:46,135 | INFO | FT ep 2/10: train_loss=2.2194, val_acc=0.5781
2026-02-13 04:01:46,190 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/MNv2_TP/global_lrv1/kr_0.7/vbp_best.pth
2026-02-13 04:01:47,251 | INFO | FT 3 [1/10009] loss=2.3449
2026-02-13 04:02:35,464 | INFO | FT 3 [501/10009] loss=2.0783
2026-02-13 04:03:22,340 | INFO | FT 3 [1001/10009] loss=2.0731
2026-02-13 04:04:08,703 | INFO | FT 3 [1501/10009] loss=2.0776
2026-02-13 04:04:55,407 | INFO | FT 3 [2001/10009] loss=2.0772
2026-02-13 04:05:41,833 | INFO | FT 3 [2501/10009] loss=2.0753
2026-02-13 04:06:28,418 | INFO | FT 3 [3001/10009] loss=2.0731
2026-02-13 04:07:14,733 | INFO | FT 3 [3501/10009] loss=2.0730
2026-02-13 04:08:01,320 | INFO | FT 3 [4001/10009] loss=2.0720
2026-02-13 04:08:47,921 | INFO | FT 3 [4501/10009] loss=2.0707
2026-02-13 04:09:34,580 | INFO | FT 3 [5001/10009] loss=2.0718
2026-02-13 04:10:21,328 | INFO | FT 3 [5501/10009] loss=2.0694
2026-02-13 04:11:07,818 | INFO | FT 3 [6001/10009] loss=2.0654
2026-02-13 04:11:54,408 | INFO | FT 3 [6501/10009] loss=2.0634
2026-02-13 04:12:41,009 | INFO | FT 3 [7001/10009] loss=2.0616
2026-02-13 04:13:27,637 | INFO | FT 3 [7501/10009] loss=2.0608
2026-02-13 04:14:14,118 | INFO | FT 3 [8001/10009] loss=2.0584
2026-02-13 04:15:00,670 | INFO | FT 3 [8501/10009] loss=2.0557
2026-02-13 04:15:47,581 | INFO | FT 3 [9001/10009] loss=2.0534
2026-02-13 04:16:34,118 | INFO | FT 3 [9501/10009] loss=2.0510
2026-02-13 04:17:20,486 | INFO | FT 3 [10001/10009] loss=2.0483
2026-02-13 04:17:21,228 | INFO | FT 3 [10009/10009] loss=2.0484
2026-02-13 04:18:28,021 | INFO | FT ep 3/10: train_loss=2.0484, val_acc=0.5944
2026-02-13 04:18:28,074 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/MNv2_TP/global_lrv1/kr_0.7/vbp_best.pth
2026-02-13 04:18:29,087 | INFO | FT 4 [1/10009] loss=1.9567
2026-02-13 04:19:17,932 | INFO | FT 4 [501/10009] loss=1.9485
2026-02-13 04:20:05,809 | INFO | FT 4 [1001/10009] loss=1.9515
2026-02-13 04:20:53,198 | INFO | FT 4 [1501/10009] loss=1.9537
2026-02-13 04:21:40,518 | INFO | FT 4 [2001/10009] loss=1.9529
2026-02-13 04:22:27,797 | INFO | FT 4 [2501/10009] loss=1.9489
2026-02-13 04:23:14,918 | INFO | FT 4 [3001/10009] loss=1.9509
2026-02-13 04:24:01,889 | INFO | FT 4 [3501/10009] loss=1.9482
2026-02-13 04:24:48,707 | INFO | FT 4 [4001/10009] loss=1.9450
2026-02-13 04:25:35,408 | INFO | FT 4 [4501/10009] loss=1.9426
2026-02-13 04:26:22,045 | INFO | FT 4 [5001/10009] loss=1.9434
2026-02-13 04:27:08,607 | INFO | FT 4 [5501/10009] loss=1.9407
2026-02-13 04:27:55,144 | INFO | FT 4 [6001/10009] loss=1.9402
2026-02-13 04:28:41,774 | INFO | FT 4 [6501/10009] loss=1.9390
2026-02-13 04:29:28,505 | INFO | FT 4 [7001/10009] loss=1.9379
2026-02-13 04:30:15,418 | INFO | FT 4 [7501/10009] loss=1.9349
2026-02-13 04:31:02,244 | INFO | FT 4 [8001/10009] loss=1.9321
2026-02-13 04:31:48,826 | INFO | FT 4 [8501/10009] loss=1.9300
2026-02-13 04:32:35,718 | INFO | FT 4 [9001/10009] loss=1.9280
2026-02-13 04:33:22,206 | INFO | FT 4 [9501/10009] loss=1.9264
2026-02-13 04:34:08,818 | INFO | FT 4 [10001/10009] loss=1.9251
2026-02-13 04:34:09,567 | INFO | FT 4 [10009/10009] loss=1.9251
2026-02-13 04:35:15,504 | INFO | FT ep 4/10: train_loss=1.9251, val_acc=0.6122
2026-02-13 04:35:15,558 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/MNv2_TP/global_lrv1/kr_0.7/vbp_best.pth
2026-02-13 04:35:16,645 | INFO | FT 5 [1/10009] loss=1.9938
2026-02-13 04:36:04,918 | INFO | FT 5 [501/10009] loss=1.8370
2026-02-13 04:36:52,275 | INFO | FT 5 [1001/10009] loss=1.8523
2026-02-13 04:37:39,555 | INFO | FT 5 [1501/10009] loss=1.8496
2026-02-13 04:38:26,908 | INFO | FT 5 [2001/10009] loss=1.8508
2026-02-13 04:39:14,008 | INFO | FT 5 [2501/10009] loss=1.8495
2026-02-13 04:40:01,308 | INFO | FT 5 [3001/10009] loss=1.8488
2026-02-13 04:40:48,173 | INFO | FT 5 [3501/10009] loss=1.8499
2026-02-13 04:41:35,118 | INFO | FT 5 [4001/10009] loss=1.8499
2026-02-13 04:42:21,818 | INFO | FT 5 [4501/10009] loss=1.8480
2026-02-13 04:43:08,509 | INFO | FT 5 [5001/10009] loss=1.8463
2026-02-13 04:43:55,018 | INFO | FT 5 [5501/10009] loss=1.8445
2026-02-13 04:44:42,041 | INFO | FT 5 [6001/10009] loss=1.8428
2026-02-13 04:45:28,610 | INFO | FT 5 [6501/10009] loss=1.8410
2026-02-13 04:46:15,378 | INFO | FT 5 [7001/10009] loss=1.8385
2026-02-13 04:47:02,226 | INFO | FT 5 [7501/10009] loss=1.8361
2026-02-13 04:47:49,038 | INFO | FT 5 [8001/10009] loss=1.8333
2026-02-13 04:48:35,946 | INFO | FT 5 [8501/10009] loss=1.8309
2026-02-13 04:49:22,860 | INFO | FT 5 [9001/10009] loss=1.8295
2026-02-13 04:50:10,353 | INFO | FT 5 [9501/10009] loss=1.8286
2026-02-13 04:50:57,552 | INFO | FT 5 [10001/10009] loss=1.8264
2026-02-13 04:50:58,294 | INFO | FT 5 [10009/10009] loss=1.8262
2026-02-13 04:52:07,198 | INFO | FT ep 5/10: train_loss=1.8262, val_acc=0.6282
2026-02-13 04:52:07,255 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/MNv2_TP/global_lrv1/kr_0.7/vbp_best.pth
2026-02-13 04:52:08,344 | INFO | FT 6 [1/10009] loss=1.9119
2026-02-13 04:52:56,549 | INFO | FT 6 [501/10009] loss=1.7657
2026-02-13 04:53:44,618 | INFO | FT 6 [1001/10009] loss=1.7670
2026-02-13 04:54:32,718 | INFO | FT 6 [1501/10009] loss=1.7626
2026-02-13 04:55:21,018 | INFO | FT 6 [2001/10009] loss=1.7649
2026-02-13 04:56:09,052 | INFO | FT 6 [2501/10009] loss=1.7634
2026-02-13 04:56:56,707 | INFO | FT 6 [3001/10009] loss=1.7598
2026-02-13 04:57:43,945 | INFO | FT 6 [3501/10009] loss=1.7607
2026-02-13 04:58:31,009 | INFO | FT 6 [4001/10009] loss=1.7602
2026-02-13 04:59:18,418 | INFO | FT 6 [4501/10009] loss=1.7582
2026-02-13 05:00:05,810 | INFO | FT 6 [5001/10009] loss=1.7558
2026-02-13 05:00:52,957 | INFO | FT 6 [5501/10009] loss=1.7530
2026-02-13 05:01:40,158 | INFO | FT 6 [6001/10009] loss=1.7521
2026-02-13 05:02:27,607 | INFO | FT 6 [6501/10009] loss=1.7509
2026-02-13 05:03:14,518 | INFO | FT 6 [7001/10009] loss=1.7500
2026-02-13 05:04:01,344 | INFO | FT 6 [7501/10009] loss=1.7485
2026-02-13 05:04:48,307 | INFO | FT 6 [8001/10009] loss=1.7476
2026-02-13 05:05:35,225 | INFO | FT 6 [8501/10009] loss=1.7456
2026-02-13 05:06:22,321 | INFO | FT 6 [9001/10009] loss=1.7432
2026-02-13 05:07:09,311 | INFO | FT 6 [9501/10009] loss=1.7411
2026-02-13 05:07:56,281 | INFO | FT 6 [10001/10009] loss=1.7393
2026-02-13 05:07:57,052 | INFO | FT 6 [10009/10009] loss=1.7392
2026-02-13 05:09:00,757 | INFO | FT ep 6/10: train_loss=1.7392, val_acc=0.6399
2026-02-13 05:09:00,807 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/MNv2_TP/global_lrv1/kr_0.7/vbp_best.pth
2026-02-13 05:09:01,805 | INFO | FT 7 [1/10009] loss=1.9405
2026-02-13 05:09:50,167 | INFO | FT 7 [501/10009] loss=1.6862
2026-02-13 05:10:38,180 | INFO | FT 7 [1001/10009] loss=1.6837
2026-02-13 05:11:25,939 | INFO | FT 7 [1501/10009] loss=1.6774
2026-02-13 05:12:13,906 | INFO | FT 7 [2001/10009] loss=1.6773
2026-02-13 05:13:01,310 | INFO | FT 7 [2501/10009] loss=1.6751
2026-02-13 05:13:48,718 | INFO | FT 7 [3001/10009] loss=1.6745
2026-02-13 05:14:35,855 | INFO | FT 7 [3501/10009] loss=1.6730
2026-02-13 05:15:23,398 | INFO | FT 7 [4001/10009] loss=1.6730
2026-02-13 05:16:10,686 | INFO | FT 7 [4501/10009] loss=1.6715
2026-02-13 05:16:57,552 | INFO | FT 7 [5001/10009] loss=1.6709
2026-02-13 05:17:44,718 | INFO | FT 7 [5501/10009] loss=1.6704
2026-02-13 05:18:32,018 | INFO | FT 7 [6001/10009] loss=1.6702
2026-02-13 05:19:19,110 | INFO | FT 7 [6501/10009] loss=1.6684
2026-02-13 05:20:06,318 | INFO | FT 7 [7001/10009] loss=1.6667
2026-02-13 05:20:53,635 | INFO | FT 7 [7501/10009] loss=1.6651
2026-02-13 05:21:40,732 | INFO | FT 7 [8001/10009] loss=1.6642
2026-02-13 05:22:28,118 | INFO | FT 7 [8501/10009] loss=1.6629
2026-02-13 05:23:15,209 | INFO | FT 7 [9001/10009] loss=1.6614
2026-02-13 05:24:02,077 | INFO | FT 7 [9501/10009] loss=1.6603
2026-02-13 05:24:49,409 | INFO | FT 7 [10001/10009] loss=1.6592
2026-02-13 05:24:50,161 | INFO | FT 7 [10009/10009] loss=1.6591
2026-02-13 05:25:56,892 | INFO | FT ep 7/10: train_loss=1.6591, val_acc=0.6473
2026-02-13 05:25:56,937 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/MNv2_TP/global_lrv1/kr_0.7/vbp_best.pth
2026-02-13 05:25:57,966 | INFO | FT 8 [1/10009] loss=1.6709
2026-02-13 05:26:45,788 | INFO | FT 8 [501/10009] loss=1.6001
2026-02-13 05:27:32,698 | INFO | FT 8 [1001/10009] loss=1.6009
2026-02-13 05:28:19,579 | INFO | FT 8 [1501/10009] loss=1.6058
2026-02-13 05:29:06,718 | INFO | FT 8 [2001/10009] loss=1.6091
2026-02-13 05:29:54,518 | INFO | FT 8 [2501/10009] loss=1.6093
2026-02-13 05:30:42,189 | INFO | FT 8 [3001/10009] loss=1.6094
2026-02-13 05:31:30,937 | INFO | FT 8 [3501/10009] loss=1.6079
2026-02-13 05:32:19,518 | INFO | FT 8 [4001/10009] loss=1.6061
2026-02-13 05:33:09,918 | INFO | FT 8 [4501/10009] loss=1.6047
2026-02-13 05:33:59,418 | INFO | FT 8 [5001/10009] loss=1.6019
2026-02-13 05:34:49,018 | INFO | FT 8 [5501/10009] loss=1.6017
2026-02-13 05:35:38,391 | INFO | FT 8 [6001/10009] loss=1.6003
2026-02-13 05:36:28,025 | INFO | FT 8 [6501/10009] loss=1.5986
2026-02-13 05:37:17,618 | INFO | FT 8 [7001/10009] loss=1.5971
2026-02-13 05:38:07,218 | INFO | FT 8 [7501/10009] loss=1.5957
2026-02-13 05:38:56,718 | INFO | FT 8 [8001/10009] loss=1.5948
2026-02-13 05:39:46,274 | INFO | FT 8 [8501/10009] loss=1.5941
2026-02-13 05:40:35,952 | INFO | FT 8 [9001/10009] loss=1.5930
2026-02-13 05:41:25,418 | INFO | FT 8 [9501/10009] loss=1.5925
2026-02-13 05:42:14,518 | INFO | FT 8 [10001/10009] loss=1.5915
2026-02-13 05:42:15,270 | INFO | FT 8 [10009/10009] loss=1.5915
2026-02-13 05:43:22,453 | INFO | FT ep 8/10: train_loss=1.5915, val_acc=0.6597
2026-02-13 05:43:22,498 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/MNv2_TP/global_lrv1/kr_0.7/vbp_best.pth
2026-02-13 05:43:23,352 | INFO | FT 9 [1/10009] loss=1.5383
2026-02-13 05:44:12,318 | INFO | FT 9 [501/10009] loss=1.5712
2026-02-13 05:45:01,296 | INFO | FT 9 [1001/10009] loss=1.5629
2026-02-13 05:45:50,318 | INFO | FT 9 [1501/10009] loss=1.5575
2026-02-13 05:46:39,221 | INFO | FT 9 [2001/10009] loss=1.5547
2026-02-13 05:47:28,618 | INFO | FT 9 [2501/10009] loss=1.5542
2026-02-13 05:48:17,218 | INFO | FT 9 [3001/10009] loss=1.5526
2026-02-13 05:49:05,918 | INFO | FT 9 [3501/10009] loss=1.5523
2026-02-13 05:49:54,107 | INFO | FT 9 [4001/10009] loss=1.5516
2026-02-13 05:50:43,344 | INFO | FT 9 [4501/10009] loss=1.5528
2026-02-13 05:51:32,918 | INFO | FT 9 [5001/10009] loss=1.5514
2026-02-13 05:52:22,218 | INFO | FT 9 [5501/10009] loss=1.5506
2026-02-13 05:53:11,218 | INFO | FT 9 [6001/10009] loss=1.5490
2026-02-13 05:54:00,308 | INFO | FT 9 [6501/10009] loss=1.5478
2026-02-13 05:54:49,118 | INFO | FT 9 [7001/10009] loss=1.5474
2026-02-13 05:55:38,118 | INFO | FT 9 [7501/10009] loss=1.5466
2026-02-13 05:56:27,166 | INFO | FT 9 [8001/10009] loss=1.5461
2026-02-13 05:57:15,618 | INFO | FT 9 [8501/10009] loss=1.5454
2026-02-13 05:58:04,318 | INFO | FT 9 [9001/10009] loss=1.5451
2026-02-13 05:58:52,768 | INFO | FT 9 [9501/10009] loss=1.5442
2026-02-13 05:59:41,188 | INFO | FT 9 [10001/10009] loss=1.5445
2026-02-13 05:59:41,944 | INFO | FT 9 [10009/10009] loss=1.5444
2026-02-13 06:00:51,477 | INFO | FT ep 9/10: train_loss=1.5444, val_acc=0.6618
2026-02-13 06:00:51,523 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/MNv2_TP/global_lrv1/kr_0.7/vbp_best.pth
2026-02-13 06:00:52,418 | INFO | FT 10 [1/10009] loss=1.6721
2026-02-13 06:01:41,518 | INFO | FT 10 [501/10009] loss=1.5343
2026-02-13 06:02:30,218 | INFO | FT 10 [1001/10009] loss=1.5239
2026-02-13 06:03:19,107 | INFO | FT 10 [1501/10009] loss=1.5240
2026-02-13 06:04:07,718 | INFO | FT 10 [2001/10009] loss=1.5223
2026-02-13 06:04:56,324 | INFO | FT 10 [2501/10009] loss=1.5256
2026-02-13 06:05:44,918 | INFO | FT 10 [3001/10009] loss=1.5258
2026-02-13 06:06:33,818 | INFO | FT 10 [3501/10009] loss=1.5255
2026-02-13 06:07:22,218 | INFO | FT 10 [4001/10009] loss=1.5265
2026-02-13 06:08:10,419 | INFO | FT 10 [4501/10009] loss=1.5262
2026-02-13 06:09:00,250 | INFO | FT 10 [5001/10009] loss=1.5267
2026-02-13 06:09:50,118 | INFO | FT 10 [5501/10009] loss=1.5261
2026-02-13 06:10:39,518 | INFO | FT 10 [6001/10009] loss=1.5264
2026-02-13 06:11:28,818 | INFO | FT 10 [6501/10009] loss=1.5252
2026-02-13 06:12:17,940 | INFO | FT 10 [7001/10009] loss=1.5257
2026-02-13 06:13:07,118 | INFO | FT 10 [7501/10009] loss=1.5246
2026-02-13 06:13:55,809 | INFO | FT 10 [8001/10009] loss=1.5240
2026-02-13 06:14:44,972 | INFO | FT 10 [8501/10009] loss=1.5241
2026-02-13 06:15:33,718 | INFO | FT 10 [9001/10009] loss=1.5231
2026-02-13 06:16:22,954 | INFO | FT 10 [9501/10009] loss=1.5230
2026-02-13 06:17:11,818 | INFO | FT 10 [10001/10009] loss=1.5233
2026-02-13 06:17:12,569 | INFO | FT 10 [10009/10009] loss=1.5232
2026-02-13 06:18:23,329 | INFO | FT ep 10/10: train_loss=1.5232, val_acc=0.6629
2026-02-13 06:18:23,376 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/MNv2_TP/global_lrv1/kr_0.7/vbp_best.pth
2026-02-13 06:19:34,108 | INFO | ============================================================
2026-02-13 06:19:34,109 | INFO | Summary
2026-02-13 06:19:34,109 | INFO | ============================================================
2026-02-13 06:19:34,109 | INFO | Base MACs:    0.32G -> Pruned: 0.24G (76.2%)
2026-02-13 06:19:34,109 | INFO | Base Params:  3.50M -> Pruned: 2.73M (78.0%)
2026-02-13 06:19:34,109 | INFO | Original Acc: 0.7187
2026-02-13 06:19:34,109 | INFO | Final Acc:    0.6629
2026-02-13 06:19:34,109 | INFO | Best Acc:     0.6629
2026-02-13 06:19:34,158 | INFO | Final model saved to /algo/NetOptimization/outputs/VBP/MNv2_TP/global_lrv1/kr_0.7/vbp_final.pth
