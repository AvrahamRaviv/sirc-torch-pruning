2026-02-13 08:28:49,536 | INFO | Logging to /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.8/vbp_imagenet.log
2026-02-13 08:28:49,536 | INFO | ============================================================
2026-02-13 08:28:49,536 | INFO | VBP ImageNet Reproduction Script
2026-02-13 08:28:49,537 | INFO | ============================================================
2026-02-13 08:28:49,537 | INFO |   model_type: cnn
2026-02-13 08:28:49,537 | INFO |   model_name: /algo/NetOptimization/outputs/VBP/ResNet50_TP/resnet50_imagenet1k.pth
2026-02-13 08:28:49,537 | INFO |   cnn_arch: resnet50
2026-02-13 08:28:49,537 | INFO |   pretrained: True
2026-02-13 08:28:49,537 | INFO |   interior_only: True
2026-02-13 08:28:49,537 | INFO |   data_path: /algo/NetOptimization/outputs/VBP/
2026-02-13 08:28:49,537 | INFO |   train_batch_size: 64
2026-02-13 08:28:49,537 | INFO |   val_batch_size: 128
2026-02-13 08:28:49,537 | INFO |   num_workers: 4
2026-02-13 08:28:49,537 | INFO |   max_batches: 200
2026-02-13 08:28:49,537 | INFO |   keep_ratio: 0.8
2026-02-13 08:28:49,537 | INFO |   global_pruning: True
2026-02-13 08:28:49,538 | INFO |   max_pruning_ratio: 1.0
2026-02-13 08:28:49,538 | INFO |   norm_per_layer: False
2026-02-13 08:28:49,538 | INFO |   no_compensation: False
2026-02-13 08:28:49,538 | INFO |   no_recalib: False
2026-02-13 08:28:49,538 | INFO |   criterion: variance
2026-02-13 08:28:49,538 | INFO |   epochs_ft: 10
2026-02-13 08:28:49,538 | INFO |   lr_ft: 0.0001
2026-02-13 08:28:49,538 | INFO |   opt_ft: adamw
2026-02-13 08:28:49,538 | INFO |   momentum_ft: 0.9
2026-02-13 08:28:49,538 | INFO |   wd_ft: None
2026-02-13 08:28:49,538 | INFO |   use_kd: True
2026-02-13 08:28:49,538 | INFO |   kd_alpha: 0.7
2026-02-13 08:28:49,538 | INFO |   kd_T: 2.0
2026-02-13 08:28:49,538 | INFO |   pat: False
2026-02-13 08:28:49,538 | INFO |   pat_steps: 5
2026-02-13 08:28:49,538 | INFO |   pat_epochs_per_step: 3
2026-02-13 08:28:49,538 | INFO |   var_loss_weight: 0.0
2026-02-13 08:28:49,538 | INFO |   sparse_mode: none
2026-02-13 08:28:49,538 | INFO |   epochs_sparse: 5
2026-02-13 08:28:49,538 | INFO |   lr_sparse: 0.0001
2026-02-13 08:28:49,538 | INFO |   l1_lambda: 0.0001
2026-02-13 08:28:49,538 | INFO |   gmp_target_sparsity: 0.5
2026-02-13 08:28:49,538 | INFO |   disable_ddp: False
2026-02-13 08:28:49,538 | INFO |   local_rank: 0
2026-02-13 08:28:49,538 | INFO |   save_dir: /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.8
2026-02-13 08:28:49,538 | INFO |   rank: 0
2026-02-13 08:28:49,538 | INFO |   world_size: 2
2026-02-13 08:28:49,539 | INFO | Loading ImageNet dataset...
2026-02-13 08:28:49,539 | INFO | Using cached sample lists for fast loading
2026-02-13 08:28:49,896 | INFO | Train samples: 1281167, Val samples: 50000
2026-02-13 08:28:52,009 | INFO | Loaded resnet50 (pretrained=True)
2026-02-13 08:28:53,442 | INFO | Baseline: 4.12G MACs, 25.56M params
2026-02-13 08:28:53,442 | INFO | Evaluating original model...
2026-02-13 08:29:59,736 | INFO | Original accuracy: 0.8035, loss: 1.4124
2026-02-13 08:29:59,759 | INFO | Created teacher model for knowledge distillation
2026-02-13 08:29:59,759 | INFO | PAT: 1 steps, per_step_keep=0.8000, epochs_per_step=0, target_keep=0.8, criterion=variance
2026-02-13 08:29:59,759 | INFO | 
============================================================
2026-02-13 08:29:59,759 | INFO | PAT Step 1/1
2026-02-13 08:29:59,759 | INFO | ============================================================
2026-02-13 08:29:59,780 | INFO | Auto-detected 53 CNN target layers for stats
2026-02-13 08:29:59,781 | INFO | Collecting activation variance statistics...
2026-02-13 08:30:19,586 | INFO | Statistics collected for 53 layers
2026-02-13 08:30:19,586 | INFO |   Conv2d: mean_var=5.515929
2026-02-13 08:30:19,586 | INFO |   Conv2d: mean_var=1.091153
2026-02-13 08:30:19,586 | INFO |   Conv2d: mean_var=2.071457
2026-02-13 08:30:19,586 | INFO |   Conv2d: mean_var=13.764833
2026-02-13 08:30:19,587 | INFO |   Conv2d: mean_var=16.704292
2026-02-13 08:30:19,743 | INFO | Variance â€” entropy=0.9314, cv=1.4995, gini=0.6153
2026-02-13 08:30:19,786 | INFO | Pruning: per_step_prune=0.2000
2026-02-13 08:30:20,270 | INFO | Pruning complete (criterion=VBP, compensation=on)
2026-02-13 08:30:20,270 | INFO | Recalibrating BN running stats...
2026-02-13 08:30:21,017 | INFO | BN recalib [1/100]
2026-02-13 08:30:21,221 | INFO | BN recalib [6/100]
2026-02-13 08:30:21,487 | INFO | BN recalib [11/100]
2026-02-13 08:30:21,823 | INFO | BN recalib [16/100]
2026-02-13 08:30:22,856 | INFO | BN recalib [21/100]
2026-02-13 08:30:23,153 | INFO | BN recalib [26/100]
2026-02-13 08:30:23,562 | INFO | BN recalib [31/100]
2026-02-13 08:30:23,878 | INFO | BN recalib [36/100]
2026-02-13 08:30:24,478 | INFO | BN recalib [41/100]
2026-02-13 08:30:24,797 | INFO | BN recalib [46/100]
2026-02-13 08:30:25,127 | INFO | BN recalib [51/100]
2026-02-13 08:30:25,458 | INFO | BN recalib [56/100]
2026-02-13 08:30:26,029 | INFO | BN recalib [61/100]
2026-02-13 08:30:26,341 | INFO | BN recalib [66/100]
2026-02-13 08:30:26,603 | INFO | BN recalib [71/100]
2026-02-13 08:30:26,920 | INFO | BN recalib [76/100]
2026-02-13 08:30:27,501 | INFO | BN recalib [81/100]
2026-02-13 08:30:27,776 | INFO | BN recalib [86/100]
2026-02-13 08:30:28,096 | INFO | BN recalib [91/100]
2026-02-13 08:30:28,390 | INFO | BN recalib [96/100]
2026-02-13 08:30:28,756 | INFO | BN recalib [100/100]
2026-02-13 08:30:29,266 | INFO | BN recalibration done (100 batches)
2026-02-13 08:31:32,785 | INFO | Step 1 retention: acc=0.7466, loss=1.7526
2026-02-13 08:31:32,785 | INFO |   cumulative_keep=0.8000, MACs=3.48G, params=18.98M
2026-02-13 08:31:32,785 | INFO | 
Post-prune fine-tuning for 10 epochs (adamw, lr=0.0001, wd=0.01)...
2026-02-13 08:31:33,869 | INFO | FT 1 [1/10009] loss=1.3436
2026-02-13 08:33:18,242 | INFO | FT 1 [501/10009] loss=1.0616
2026-02-13 08:35:03,679 | INFO | FT 1 [1001/10009] loss=1.0398
2026-02-13 08:36:49,119 | INFO | FT 1 [1501/10009] loss=1.0283
2026-02-13 08:38:34,472 | INFO | FT 1 [2001/10009] loss=1.0192
2026-02-13 08:40:19,768 | INFO | FT 1 [2501/10009] loss=1.0159
2026-02-13 08:42:05,084 | INFO | FT 1 [3001/10009] loss=1.0122
2026-02-13 08:43:50,364 | INFO | FT 1 [3501/10009] loss=1.0104
2026-02-13 08:45:35,887 | INFO | FT 1 [4001/10009] loss=1.0071
2026-02-13 08:47:21,252 | INFO | FT 1 [4501/10009] loss=1.0063
2026-02-13 08:49:06,577 | INFO | FT 1 [5001/10009] loss=1.0041
2026-02-13 08:50:51,815 | INFO | FT 1 [5501/10009] loss=1.0022
2026-02-13 08:52:36,954 | INFO | FT 1 [6001/10009] loss=1.0010
2026-02-13 08:54:21,395 | INFO | FT 1 [6501/10009] loss=0.9998
2026-02-13 08:56:06,568 | INFO | FT 1 [7001/10009] loss=0.9986
2026-02-13 08:57:51,691 | INFO | FT 1 [7501/10009] loss=0.9972
2026-02-13 08:59:36,784 | INFO | FT 1 [8001/10009] loss=0.9966
2026-02-13 09:01:21,872 | INFO | FT 1 [8501/10009] loss=0.9961
2026-02-13 09:03:06,723 | INFO | FT 1 [9001/10009] loss=0.9951
2026-02-13 09:04:51,666 | INFO | FT 1 [9501/10009] loss=0.9937
2026-02-13 09:06:36,501 | INFO | FT 1 [10001/10009] loss=0.9927
2026-02-13 09:06:38,227 | INFO | FT 1 [10009/10009] loss=0.9927
2026-02-13 09:07:44,733 | INFO | FT ep 1/10: train_loss=0.9927, val_acc=0.7652
2026-02-13 09:07:44,881 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.8/vbp_best.pth
2026-02-13 09:07:45,852 | INFO | FT 2 [1/10009] loss=0.7194
2026-02-13 09:09:30,636 | INFO | FT 2 [501/10009] loss=0.9299
2026-02-13 09:11:15,552 | INFO | FT 2 [1001/10009] loss=0.9370
2026-02-13 09:13:01,224 | INFO | FT 2 [1501/10009] loss=0.9390
2026-02-13 09:14:46,773 | INFO | FT 2 [2001/10009] loss=0.9407
2026-02-13 09:16:32,267 | INFO | FT 2 [2501/10009] loss=0.9405
2026-02-13 09:18:17,821 | INFO | FT 2 [3001/10009] loss=0.9398
2026-02-13 09:20:02,813 | INFO | FT 2 [3501/10009] loss=0.9402
2026-02-13 09:21:48,093 | INFO | FT 2 [4001/10009] loss=0.9418
2026-02-13 09:23:33,548 | INFO | FT 2 [4501/10009] loss=0.9421
2026-02-13 09:25:18,932 | INFO | FT 2 [5001/10009] loss=0.9427
2026-02-13 09:27:04,198 | INFO | FT 2 [5501/10009] loss=0.9429
2026-02-13 09:28:49,690 | INFO | FT 2 [6001/10009] loss=0.9429
2026-02-13 09:30:34,857 | INFO | FT 2 [6501/10009] loss=0.9432
2026-02-13 09:32:19,598 | INFO | FT 2 [7001/10009] loss=0.9431
2026-02-13 09:34:04,535 | INFO | FT 2 [7501/10009] loss=0.9433
2026-02-13 09:35:50,135 | INFO | FT 2 [8001/10009] loss=0.9433
2026-02-13 09:37:35,790 | INFO | FT 2 [8501/10009] loss=0.9433
2026-02-13 09:39:21,403 | INFO | FT 2 [9001/10009] loss=0.9438
2026-02-13 09:41:06,740 | INFO | FT 2 [9501/10009] loss=0.9439
2026-02-13 09:42:52,126 | INFO | FT 2 [10001/10009] loss=0.9436
2026-02-13 09:42:53,830 | INFO | FT 2 [10009/10009] loss=0.9436
2026-02-13 09:44:00,406 | INFO | FT ep 2/10: train_loss=0.9436, val_acc=0.7675
2026-02-13 09:44:00,562 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.8/vbp_best.pth
2026-02-13 09:44:01,553 | INFO | FT 3 [1/10009] loss=1.1876
2026-02-13 09:45:46,245 | INFO | FT 3 [501/10009] loss=0.9077
2026-02-13 09:47:31,455 | INFO | FT 3 [1001/10009] loss=0.8995
2026-02-13 09:49:16,824 | INFO | FT 3 [1501/10009] loss=0.9026
2026-02-13 09:51:02,111 | INFO | FT 3 [2001/10009] loss=0.9043
2026-02-13 09:52:47,358 | INFO | FT 3 [2501/10009] loss=0.9059
2026-02-13 09:54:32,697 | INFO | FT 3 [3001/10009] loss=0.9063
2026-02-13 09:56:18,474 | INFO | FT 3 [3501/10009] loss=0.9077
2026-02-13 09:58:04,088 | INFO | FT 3 [4001/10009] loss=0.9098
2026-02-13 09:59:49,556 | INFO | FT 3 [4501/10009] loss=0.9107
2026-02-13 10:01:34,862 | INFO | FT 3 [5001/10009] loss=0.9119
2026-02-13 10:03:20,234 | INFO | FT 3 [5501/10009] loss=0.9118
2026-02-13 10:05:05,781 | INFO | FT 3 [6001/10009] loss=0.9108
2026-02-13 10:06:51,599 | INFO | FT 3 [6501/10009] loss=0.9113
2026-02-13 10:08:37,167 | INFO | FT 3 [7001/10009] loss=0.9122
2026-02-13 10:10:22,334 | INFO | FT 3 [7501/10009] loss=0.9122
2026-02-13 10:12:06,760 | INFO | FT 3 [8001/10009] loss=0.9122
2026-02-13 10:13:52,252 | INFO | FT 3 [8501/10009] loss=0.9129
2026-02-13 10:15:37,683 | INFO | FT 3 [9001/10009] loss=0.9126
2026-02-13 10:17:23,093 | INFO | FT 3 [9501/10009] loss=0.9127
2026-02-13 10:19:08,399 | INFO | FT 3 [10001/10009] loss=0.9127
2026-02-13 10:19:10,120 | INFO | FT 3 [10009/10009] loss=0.9127
2026-02-13 10:20:15,656 | INFO | FT ep 3/10: train_loss=0.9127, val_acc=0.7712
2026-02-13 10:20:15,812 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.8/vbp_best.pth
2026-02-13 10:20:16,798 | INFO | FT 4 [1/10009] loss=1.0311
2026-02-13 10:22:01,621 | INFO | FT 4 [501/10009] loss=0.8684
2026-02-13 10:23:46,589 | INFO | FT 4 [1001/10009] loss=0.8726
2026-02-13 10:25:31,729 | INFO | FT 4 [1501/10009] loss=0.8732
2026-02-13 10:27:17,312 | INFO | FT 4 [2001/10009] loss=0.8735
2026-02-13 10:29:02,873 | INFO | FT 4 [2501/10009] loss=0.8752
2026-02-13 10:30:48,555 | INFO | FT 4 [3001/10009] loss=0.8769
2026-02-13 10:32:34,104 | INFO | FT 4 [3501/10009] loss=0.8780
2026-02-13 10:34:19,463 | INFO | FT 4 [4001/10009] loss=0.8783
2026-02-13 10:36:04,849 | INFO | FT 4 [4501/10009] loss=0.8787
2026-02-13 10:37:50,640 | INFO | FT 4 [5001/10009] loss=0.8798
2026-02-13 10:39:36,070 | INFO | FT 4 [5501/10009] loss=0.8795
2026-02-13 10:41:21,488 | INFO | FT 4 [6001/10009] loss=0.8797
2026-02-13 10:43:06,794 | INFO | FT 4 [6501/10009] loss=0.8802
2026-02-13 10:44:52,197 | INFO | FT 4 [7001/10009] loss=0.8801
2026-02-13 10:46:37,919 | INFO | FT 4 [7501/10009] loss=0.8794
2026-02-13 10:48:23,507 | INFO | FT 4 [8001/10009] loss=0.8789
2026-02-13 10:50:07,940 | INFO | FT 4 [8501/10009] loss=0.8790
2026-02-13 10:51:53,532 | INFO | FT 4 [9001/10009] loss=0.8789
2026-02-13 10:53:38,387 | INFO | FT 4 [9501/10009] loss=0.8789
2026-02-13 10:55:23,689 | INFO | FT 4 [10001/10009] loss=0.8791
2026-02-13 10:55:25,386 | INFO | FT 4 [10009/10009] loss=0.8790
2026-02-13 10:56:33,617 | INFO | FT ep 4/10: train_loss=0.8790, val_acc=0.7749
2026-02-13 10:56:33,774 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.8/vbp_best.pth
2026-02-13 10:56:34,781 | INFO | FT 5 [1/10009] loss=1.0078
2026-02-13 10:58:18,948 | INFO | FT 5 [501/10009] loss=0.8370
2026-02-13 11:00:03,791 | INFO | FT 5 [1001/10009] loss=0.8433
2026-02-13 11:01:48,864 | INFO | FT 5 [1501/10009] loss=0.8443
2026-02-13 11:03:33,842 | INFO | FT 5 [2001/10009] loss=0.8449
2026-02-13 11:05:18,597 | INFO | FT 5 [2501/10009] loss=0.8440
2026-02-13 11:07:03,313 | INFO | FT 5 [3001/10009] loss=0.8422
2026-02-13 11:08:48,428 | INFO | FT 5 [3501/10009] loss=0.8417
2026-02-13 11:10:33,495 | INFO | FT 5 [4001/10009] loss=0.8437
2026-02-13 11:12:18,700 | INFO | FT 5 [4501/10009] loss=0.8447
2026-02-13 11:14:03,619 | INFO | FT 5 [5001/10009] loss=0.8445
2026-02-13 11:15:48,671 | INFO | FT 5 [5501/10009] loss=0.8441
2026-02-13 11:17:33,616 | INFO | FT 5 [6001/10009] loss=0.8442
2026-02-13 11:19:18,402 | INFO | FT 5 [6501/10009] loss=0.8438
2026-02-13 11:21:03,375 | INFO | FT 5 [7001/10009] loss=0.8431
2026-02-13 11:22:48,497 | INFO | FT 5 [7501/10009] loss=0.8430
2026-02-13 11:24:33,495 | INFO | FT 5 [8001/10009] loss=0.8425
2026-02-13 11:26:18,403 | INFO | FT 5 [8501/10009] loss=0.8422
2026-02-13 11:28:02,538 | INFO | FT 5 [9001/10009] loss=0.8425
2026-02-13 11:29:47,470 | INFO | FT 5 [9501/10009] loss=0.8427
2026-02-13 11:31:32,654 | INFO | FT 5 [10001/10009] loss=0.8424
2026-02-13 11:31:34,363 | INFO | FT 5 [10009/10009] loss=0.8424
2026-02-13 11:32:41,388 | INFO | FT ep 5/10: train_loss=0.8424, val_acc=0.7806
2026-02-13 11:32:41,563 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.8/vbp_best.pth
2026-02-13 11:32:42,606 | INFO | FT 6 [1/10009] loss=0.8942
2026-02-13 11:34:27,326 | INFO | FT 6 [501/10009] loss=0.8079
2026-02-13 11:36:12,611 | INFO | FT 6 [1001/10009] loss=0.8062
2026-02-13 11:37:58,104 | INFO | FT 6 [1501/10009] loss=0.8077
2026-02-13 11:39:43,534 | INFO | FT 6 [2001/10009] loss=0.8093
2026-02-13 11:41:28,880 | INFO | FT 6 [2501/10009] loss=0.8086
2026-02-13 11:43:14,178 | INFO | FT 6 [3001/10009] loss=0.8063
2026-02-13 11:44:59,146 | INFO | FT 6 [3501/10009] loss=0.8074
2026-02-13 11:46:44,516 | INFO | FT 6 [4001/10009] loss=0.8081
2026-02-13 11:48:29,854 | INFO | FT 6 [4501/10009] loss=0.8081
2026-02-13 11:50:15,115 | INFO | FT 6 [5001/10009] loss=0.8080
2026-02-13 11:52:00,572 | INFO | FT 6 [5501/10009] loss=0.8084
2026-02-13 11:53:45,807 | INFO | FT 6 [6001/10009] loss=0.8079
2026-02-13 11:55:31,240 | INFO | FT 6 [6501/10009] loss=0.8080
2026-02-13 11:57:16,535 | INFO | FT 6 [7001/10009] loss=0.8085
2026-02-13 11:59:01,708 | INFO | FT 6 [7501/10009] loss=0.8086
2026-02-13 12:00:46,727 | INFO | FT 6 [8001/10009] loss=0.8092
2026-02-13 12:02:31,562 | INFO | FT 6 [8501/10009] loss=0.8087
2026-02-13 12:04:16,856 | INFO | FT 6 [9001/10009] loss=0.8084
2026-02-13 12:06:01,599 | INFO | FT 6 [9501/10009] loss=0.8080
2026-02-13 12:07:46,416 | INFO | FT 6 [10001/10009] loss=0.8072
2026-02-13 12:07:48,110 | INFO | FT 6 [10009/10009] loss=0.8071
2026-02-13 12:08:50,464 | INFO | FT ep 6/10: train_loss=0.8071, val_acc=0.7840
2026-02-13 12:08:50,624 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.8/vbp_best.pth
2026-02-13 12:08:51,571 | INFO | FT 7 [1/10009] loss=0.8793
2026-02-13 12:10:36,168 | INFO | FT 7 [501/10009] loss=0.7872
2026-02-13 12:12:21,571 | INFO | FT 7 [1001/10009] loss=0.7854
2026-02-13 12:14:07,183 | INFO | FT 7 [1501/10009] loss=0.7836
2026-02-13 12:15:52,630 | INFO | FT 7 [2001/10009] loss=0.7838
2026-02-13 12:17:37,661 | INFO | FT 7 [2501/10009] loss=0.7828
2026-02-13 12:19:22,705 | INFO | FT 7 [3001/10009] loss=0.7824
2026-02-13 12:21:07,798 | INFO | FT 7 [3501/10009] loss=0.7806
2026-02-13 12:22:52,862 | INFO | FT 7 [4001/10009] loss=0.7816
2026-02-13 12:24:37,748 | INFO | FT 7 [4501/10009] loss=0.7812
2026-02-13 12:26:22,764 | INFO | FT 7 [5001/10009] loss=0.7805
2026-02-13 12:28:07,845 | INFO | FT 7 [5501/10009] loss=0.7792
2026-02-13 12:29:52,843 | INFO | FT 7 [6001/10009] loss=0.7795
2026-02-13 12:31:37,798 | INFO | FT 7 [6501/10009] loss=0.7796
2026-02-13 12:33:22,893 | INFO | FT 7 [7001/10009] loss=0.7796
2026-02-13 12:35:08,260 | INFO | FT 7 [7501/10009] loss=0.7792
2026-02-13 12:36:53,500 | INFO | FT 7 [8001/10009] loss=0.7786
2026-02-13 12:38:38,777 | INFO | FT 7 [8501/10009] loss=0.7777
