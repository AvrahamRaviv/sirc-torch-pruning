2026-02-13 06:19:56,178 | INFO | Logging to /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.9/vbp_imagenet.log
2026-02-13 06:19:56,178 | INFO | ============================================================
2026-02-13 06:19:56,178 | INFO | VBP ImageNet Reproduction Script
2026-02-13 06:19:56,178 | INFO | ============================================================
2026-02-13 06:19:56,178 | INFO |   model_type: cnn
2026-02-13 06:19:56,178 | INFO |   model_name: /algo/NetOptimization/outputs/VBP/ResNet50_TP/resnet50_imagenet1k.pth
2026-02-13 06:19:56,178 | INFO |   cnn_arch: resnet50
2026-02-13 06:19:56,178 | INFO |   pretrained: True
2026-02-13 06:19:56,178 | INFO |   interior_only: True
2026-02-13 06:19:56,179 | INFO |   data_path: /algo/NetOptimization/outputs/VBP/
2026-02-13 06:19:56,179 | INFO |   train_batch_size: 64
2026-02-13 06:19:56,179 | INFO |   val_batch_size: 128
2026-02-13 06:19:56,179 | INFO |   num_workers: 4
2026-02-13 06:19:56,179 | INFO |   max_batches: 200
2026-02-13 06:19:56,179 | INFO |   keep_ratio: 0.9
2026-02-13 06:19:56,179 | INFO |   global_pruning: True
2026-02-13 06:19:56,179 | INFO |   max_pruning_ratio: 1.0
2026-02-13 06:19:56,179 | INFO |   norm_per_layer: False
2026-02-13 06:19:56,179 | INFO |   no_compensation: False
2026-02-13 06:19:56,179 | INFO |   no_recalib: False
2026-02-13 06:19:56,179 | INFO |   criterion: variance
2026-02-13 06:19:56,179 | INFO |   epochs_ft: 10
2026-02-13 06:19:56,179 | INFO |   lr_ft: 0.0001
2026-02-13 06:19:56,179 | INFO |   opt_ft: adamw
2026-02-13 06:19:56,179 | INFO |   momentum_ft: 0.9
2026-02-13 06:19:56,179 | INFO |   wd_ft: None
2026-02-13 06:19:56,179 | INFO |   use_kd: True
2026-02-13 06:19:56,179 | INFO |   kd_alpha: 0.7
2026-02-13 06:19:56,179 | INFO |   kd_T: 2.0
2026-02-13 06:19:56,179 | INFO |   pat: False
2026-02-13 06:19:56,179 | INFO |   pat_steps: 5
2026-02-13 06:19:56,180 | INFO |   pat_epochs_per_step: 3
2026-02-13 06:19:56,180 | INFO |   var_loss_weight: 0.0
2026-02-13 06:19:56,180 | INFO |   sparse_mode: none
2026-02-13 06:19:56,180 | INFO |   epochs_sparse: 5
2026-02-13 06:19:56,180 | INFO |   lr_sparse: 0.0001
2026-02-13 06:19:56,180 | INFO |   l1_lambda: 0.0001
2026-02-13 06:19:56,180 | INFO |   gmp_target_sparsity: 0.5
2026-02-13 06:19:56,180 | INFO |   disable_ddp: False
2026-02-13 06:19:56,180 | INFO |   local_rank: 0
2026-02-13 06:19:56,180 | INFO |   save_dir: /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.9
2026-02-13 06:19:56,180 | INFO |   rank: 0
2026-02-13 06:19:56,181 | INFO |   world_size: 2
2026-02-13 06:19:56,181 | INFO | Loading ImageNet dataset...
2026-02-13 06:19:56,181 | INFO | Using cached sample lists for fast loading
2026-02-13 06:19:56,531 | INFO | Train samples: 1281167, Val samples: 50000
2026-02-13 06:19:58,835 | INFO | Loaded resnet50 (pretrained=True)
2026-02-13 06:20:00,243 | INFO | Baseline: 4.12G MACs, 25.56M params
2026-02-13 06:20:00,244 | INFO | Evaluating original model...
2026-02-13 06:21:09,892 | INFO | Original accuracy: 0.8035, loss: 1.4124
2026-02-13 06:21:09,917 | INFO | Created teacher model for knowledge distillation
2026-02-13 06:21:09,917 | INFO | PAT: 1 steps, per_step_keep=0.9000, epochs_per_step=0, target_keep=0.9, criterion=variance
2026-02-13 06:21:09,917 | INFO | 
============================================================
2026-02-13 06:21:09,917 | INFO | PAT Step 1/1
2026-02-13 06:21:09,917 | INFO | ============================================================
2026-02-13 06:21:09,940 | INFO | Auto-detected 53 CNN target layers for stats
2026-02-13 06:21:09,940 | INFO | Collecting activation variance statistics...
2026-02-13 06:21:30,017 | INFO | Statistics collected for 53 layers
2026-02-13 06:21:30,017 | INFO |   Conv2d: mean_var=5.524101
2026-02-13 06:21:30,017 | INFO |   Conv2d: mean_var=1.092739
2026-02-13 06:21:30,017 | INFO |   Conv2d: mean_var=2.074011
2026-02-13 06:21:30,018 | INFO |   Conv2d: mean_var=13.783492
2026-02-13 06:21:30,018 | INFO |   Conv2d: mean_var=16.726612
2026-02-13 06:21:30,182 | INFO | Variance â€” entropy=0.9314, cv=1.5003, gini=0.6154
2026-02-13 06:21:30,227 | INFO | Pruning: per_step_prune=0.1000
2026-02-13 06:21:30,705 | INFO | Pruning complete (criterion=VBP, compensation=on)
2026-02-13 06:21:30,705 | INFO | Recalibrating BN running stats...
2026-02-13 06:21:31,436 | INFO | BN recalib [1/100]
2026-02-13 06:21:31,708 | INFO | BN recalib [6/100]
2026-02-13 06:21:32,024 | INFO | BN recalib [11/100]
2026-02-13 06:21:32,890 | INFO | BN recalib [16/100]
2026-02-13 06:21:33,301 | INFO | BN recalib [21/100]
2026-02-13 06:21:33,768 | INFO | BN recalib [26/100]
2026-02-13 06:21:34,062 | INFO | BN recalib [31/100]
2026-02-13 06:21:34,431 | INFO | BN recalib [36/100]
2026-02-13 06:21:34,881 | INFO | BN recalib [41/100]
2026-02-13 06:21:35,285 | INFO | BN recalib [46/100]
2026-02-13 06:21:35,586 | INFO | BN recalib [51/100]
2026-02-13 06:21:36,142 | INFO | BN recalib [56/100]
2026-02-13 06:21:36,474 | INFO | BN recalib [61/100]
2026-02-13 06:21:36,775 | INFO | BN recalib [66/100]
2026-02-13 06:21:37,139 | INFO | BN recalib [71/100]
2026-02-13 06:21:37,634 | INFO | BN recalib [76/100]
2026-02-13 06:21:37,954 | INFO | BN recalib [81/100]
2026-02-13 06:21:38,243 | INFO | BN recalib [86/100]
2026-02-13 06:21:38,649 | INFO | BN recalib [91/100]
2026-02-13 06:21:39,108 | INFO | BN recalib [96/100]
2026-02-13 06:21:39,388 | INFO | BN recalib [100/100]
2026-02-13 06:21:39,850 | INFO | BN recalibration done (100 batches)
2026-02-13 06:22:48,417 | INFO | Step 1 retention: acc=0.7620, loss=1.4301
2026-02-13 06:22:48,418 | INFO |   cumulative_keep=0.9000, MACs=3.79G, params=21.72M
2026-02-13 06:22:48,418 | INFO | 
Post-prune fine-tuning for 10 epochs (adamw, lr=0.0001, wd=0.01)...
2026-02-13 06:22:49,543 | INFO | FT 1 [1/10009] loss=1.0613
2026-02-13 06:24:38,944 | INFO | FT 1 [501/10009] loss=0.9666
2026-02-13 06:26:28,918 | INFO | FT 1 [1001/10009] loss=0.9558
2026-02-13 06:28:18,796 | INFO | FT 1 [1501/10009] loss=0.9503
2026-02-13 06:30:08,626 | INFO | FT 1 [2001/10009] loss=0.9457
2026-02-13 06:31:58,451 | INFO | FT 1 [2501/10009] loss=0.9447
2026-02-13 06:33:48,351 | INFO | FT 1 [3001/10009] loss=0.9451
2026-02-13 06:35:38,406 | INFO | FT 1 [3501/10009] loss=0.9444
2026-02-13 06:37:28,446 | INFO | FT 1 [4001/10009] loss=0.9430
2026-02-13 06:39:18,540 | INFO | FT 1 [4501/10009] loss=0.9419
2026-02-13 06:41:08,523 | INFO | FT 1 [5001/10009] loss=0.9426
2026-02-13 06:42:58,996 | INFO | FT 1 [5501/10009] loss=0.9418
2026-02-13 06:44:48,788 | INFO | FT 1 [6001/10009] loss=0.9417
2026-02-13 06:46:39,027 | INFO | FT 1 [6501/10009] loss=0.9409
2026-02-13 06:48:29,129 | INFO | FT 1 [7001/10009] loss=0.9410
2026-02-13 06:50:19,193 | INFO | FT 1 [7501/10009] loss=0.9406
2026-02-13 06:52:09,183 | INFO | FT 1 [8001/10009] loss=0.9408
2026-02-13 06:53:59,141 | INFO | FT 1 [8501/10009] loss=0.9406
2026-02-13 06:55:49,019 | INFO | FT 1 [9001/10009] loss=0.9400
2026-02-13 06:57:38,894 | INFO | FT 1 [9501/10009] loss=0.9395
2026-02-13 06:59:28,907 | INFO | FT 1 [10001/10009] loss=0.9396
2026-02-13 06:59:30,694 | INFO | FT 1 [10009/10009] loss=0.9396
2026-02-13 07:00:34,617 | INFO | FT ep 1/10: train_loss=0.9396, val_acc=0.7703
2026-02-13 07:00:34,788 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.9/vbp_best.pth
2026-02-13 07:00:35,733 | INFO | FT 2 [1/10009] loss=0.8281
2026-02-13 07:02:25,386 | INFO | FT 2 [501/10009] loss=0.8876
2026-02-13 07:04:15,271 | INFO | FT 2 [1001/10009] loss=0.8921
2026-02-13 07:06:05,343 | INFO | FT 2 [1501/10009] loss=0.8944
2026-02-13 07:07:55,282 | INFO | FT 2 [2001/10009] loss=0.8961
2026-02-13 07:09:45,280 | INFO | FT 2 [2501/10009] loss=0.8973
2026-02-13 07:11:35,208 | INFO | FT 2 [3001/10009] loss=0.8957
2026-02-13 07:13:25,200 | INFO | FT 2 [3501/10009] loss=0.8966
2026-02-13 07:15:15,178 | INFO | FT 2 [4001/10009] loss=0.8981
2026-02-13 07:17:05,093 | INFO | FT 2 [4501/10009] loss=0.8988
2026-02-13 07:18:55,417 | INFO | FT 2 [5001/10009] loss=0.8998
2026-02-13 07:20:44,970 | INFO | FT 2 [5501/10009] loss=0.9005
2026-02-13 07:22:35,202 | INFO | FT 2 [6001/10009] loss=0.9011
2026-02-13 07:24:25,349 | INFO | FT 2 [6501/10009] loss=0.9023
2026-02-13 07:26:15,326 | INFO | FT 2 [7001/10009] loss=0.9022
2026-02-13 07:28:05,304 | INFO | FT 2 [7501/10009] loss=0.9025
2026-02-13 07:29:55,460 | INFO | FT 2 [8001/10009] loss=0.9027
2026-02-13 07:31:45,470 | INFO | FT 2 [8501/10009] loss=0.9029
2026-02-13 07:33:35,559 | INFO | FT 2 [9001/10009] loss=0.9037
2026-02-13 07:35:25,578 | INFO | FT 2 [9501/10009] loss=0.9040
2026-02-13 07:37:16,025 | INFO | FT 2 [10001/10009] loss=0.9046
2026-02-13 07:37:17,802 | INFO | FT 2 [10009/10009] loss=0.9046
2026-02-13 07:38:25,196 | INFO | FT ep 2/10: train_loss=0.9046, val_acc=0.7720
2026-02-13 07:38:25,382 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.9/vbp_best.pth
2026-02-13 07:38:26,389 | INFO | FT 3 [1/10009] loss=0.9170
2026-02-13 07:40:16,382 | INFO | FT 3 [501/10009] loss=0.8551
2026-02-13 07:42:06,677 | INFO | FT 3 [1001/10009] loss=0.8585
2026-02-13 07:43:56,827 | INFO | FT 3 [1501/10009] loss=0.8653
2026-02-13 07:45:47,007 | INFO | FT 3 [2001/10009] loss=0.8655
2026-02-13 07:47:37,123 | INFO | FT 3 [2501/10009] loss=0.8659
2026-02-13 07:49:27,365 | INFO | FT 3 [3001/10009] loss=0.8669
2026-02-13 07:51:17,577 | INFO | FT 3 [3501/10009] loss=0.8680
2026-02-13 07:53:07,713 | INFO | FT 3 [4001/10009] loss=0.8691
2026-02-13 07:54:57,927 | INFO | FT 3 [4501/10009] loss=0.8697
2026-02-13 07:56:47,519 | INFO | FT 3 [5001/10009] loss=0.8716
2026-02-13 07:58:37,505 | INFO | FT 3 [5501/10009] loss=0.8713
2026-02-13 08:00:27,573 | INFO | FT 3 [6001/10009] loss=0.8721
2026-02-13 08:02:17,556 | INFO | FT 3 [6501/10009] loss=0.8731
2026-02-13 08:04:07,580 | INFO | FT 3 [7001/10009] loss=0.8739
2026-02-13 08:05:57,574 | INFO | FT 3 [7501/10009] loss=0.8742
2026-02-13 08:07:47,716 | INFO | FT 3 [8001/10009] loss=0.8743
2026-02-13 08:09:37,702 | INFO | FT 3 [8501/10009] loss=0.8747
2026-02-13 08:11:27,904 | INFO | FT 3 [9001/10009] loss=0.8745
2026-02-13 08:13:18,316 | INFO | FT 3 [9501/10009] loss=0.8742
2026-02-13 08:15:07,845 | INFO | FT 3 [10001/10009] loss=0.8743
2026-02-13 08:15:09,630 | INFO | FT 3 [10009/10009] loss=0.8743
2026-02-13 08:16:17,726 | INFO | FT ep 3/10: train_loss=0.8743, val_acc=0.7752
2026-02-13 08:16:17,951 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.9/vbp_best.pth
2026-02-13 08:16:18,973 | INFO | FT 4 [1/10009] loss=0.8752
2026-02-13 08:18:08,928 | INFO | FT 4 [501/10009] loss=0.8312
2026-02-13 08:19:58,947 | INFO | FT 4 [1001/10009] loss=0.8323
2026-02-13 08:21:49,059 | INFO | FT 4 [1501/10009] loss=0.8327
2026-02-13 08:23:39,151 | INFO | FT 4 [2001/10009] loss=0.8328
2026-02-13 08:25:29,359 | INFO | FT 4 [2501/10009] loss=0.8348
2026-02-13 08:27:19,410 | INFO | FT 4 [3001/10009] loss=0.8371
2026-02-13 08:29:09,387 | INFO | FT 4 [3501/10009] loss=0.8382
2026-02-13 08:30:59,955 | INFO | FT 4 [4001/10009] loss=0.8383
2026-02-13 08:32:51,269 | INFO | FT 4 [4501/10009] loss=0.8393
2026-02-13 08:34:42,649 | INFO | FT 4 [5001/10009] loss=0.8407
2026-02-13 08:36:33,845 | INFO | FT 4 [5501/10009] loss=0.8415
2026-02-13 08:38:25,035 | INFO | FT 4 [6001/10009] loss=0.8423
2026-02-13 08:40:16,281 | INFO | FT 4 [6501/10009] loss=0.8421
2026-02-13 08:42:07,631 | INFO | FT 4 [7001/10009] loss=0.8418
2026-02-13 08:43:58,900 | INFO | FT 4 [7501/10009] loss=0.8417
2026-02-13 08:45:50,335 | INFO | FT 4 [8001/10009] loss=0.8414
2026-02-13 08:47:41,636 | INFO | FT 4 [8501/10009] loss=0.8414
2026-02-13 08:49:33,132 | INFO | FT 4 [9001/10009] loss=0.8412
2026-02-13 08:51:24,403 | INFO | FT 4 [9501/10009] loss=0.8413
2026-02-13 08:53:16,020 | INFO | FT 4 [10001/10009] loss=0.8412
2026-02-13 08:53:17,849 | INFO | FT 4 [10009/10009] loss=0.8413
2026-02-13 08:54:23,139 | INFO | FT ep 4/10: train_loss=0.8413, val_acc=0.7784
2026-02-13 08:54:23,330 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.9/vbp_best.pth
2026-02-13 08:54:24,377 | INFO | FT 5 [1/10009] loss=0.9421
2026-02-13 08:56:15,331 | INFO | FT 5 [501/10009] loss=0.7949
2026-02-13 08:58:06,289 | INFO | FT 5 [1001/10009] loss=0.8007
2026-02-13 08:59:57,358 | INFO | FT 5 [1501/10009] loss=0.8024
2026-02-13 09:01:48,071 | INFO | FT 5 [2001/10009] loss=0.7998
2026-02-13 09:03:39,940 | INFO | FT 5 [2501/10009] loss=0.8003
2026-02-13 09:05:31,721 | INFO | FT 5 [3001/10009] loss=0.7998
2026-02-13 09:07:23,201 | INFO | FT 5 [3501/10009] loss=0.8004
2026-02-13 09:09:14,933 | INFO | FT 5 [4001/10009] loss=0.8017
2026-02-13 09:11:06,957 | INFO | FT 5 [4501/10009] loss=0.8026
2026-02-13 09:12:59,222 | INFO | FT 5 [5001/10009] loss=0.8021
2026-02-13 09:14:51,537 | INFO | FT 5 [5501/10009] loss=0.8026
2026-02-13 09:16:43,684 | INFO | FT 5 [6001/10009] loss=0.8037
2026-02-13 09:18:35,833 | INFO | FT 5 [6501/10009] loss=0.8037
2026-02-13 09:20:28,070 | INFO | FT 5 [7001/10009] loss=0.8035
2026-02-13 09:22:20,171 | INFO | FT 5 [7501/10009] loss=0.8040
2026-02-13 09:24:12,268 | INFO | FT 5 [8001/10009] loss=0.8038
2026-02-13 09:26:04,611 | INFO | FT 5 [8501/10009] loss=0.8036
2026-02-13 09:27:56,711 | INFO | FT 5 [9001/10009] loss=0.8036
2026-02-13 09:29:48,918 | INFO | FT 5 [9501/10009] loss=0.8040
2026-02-13 09:31:40,967 | INFO | FT 5 [10001/10009] loss=0.8040
2026-02-13 09:31:42,794 | INFO | FT 5 [10009/10009] loss=0.8040
2026-02-13 09:32:50,273 | INFO | FT ep 5/10: train_loss=0.8040, val_acc=0.7828
2026-02-13 09:32:50,486 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.9/vbp_best.pth
2026-02-13 09:32:51,574 | INFO | FT 6 [1/10009] loss=0.9504
2026-02-13 09:34:43,296 | INFO | FT 6 [501/10009] loss=0.7738
2026-02-13 09:36:35,060 | INFO | FT 6 [1001/10009] loss=0.7754
2026-02-13 09:38:26,550 | INFO | FT 6 [1501/10009] loss=0.7725
2026-02-13 09:40:18,745 | INFO | FT 6 [2001/10009] loss=0.7732
2026-02-13 09:42:10,759 | INFO | FT 6 [2501/10009] loss=0.7748
2026-02-13 09:44:02,403 | INFO | FT 6 [3001/10009] loss=0.7735
2026-02-13 09:45:54,723 | INFO | FT 6 [3501/10009] loss=0.7725
2026-02-13 09:47:46,446 | INFO | FT 6 [4001/10009] loss=0.7728
2026-02-13 09:49:38,358 | INFO | FT 6 [4501/10009] loss=0.7731
2026-02-13 09:51:30,505 | INFO | FT 6 [5001/10009] loss=0.7734
2026-02-13 09:53:22,537 | INFO | FT 6 [5501/10009] loss=0.7736
2026-02-13 09:55:14,706 | INFO | FT 6 [6001/10009] loss=0.7732
2026-02-13 09:57:06,915 | INFO | FT 6 [6501/10009] loss=0.7736
2026-02-13 09:58:59,116 | INFO | FT 6 [7001/10009] loss=0.7743
2026-02-13 10:00:51,202 | INFO | FT 6 [7501/10009] loss=0.7739
2026-02-13 10:02:43,368 | INFO | FT 6 [8001/10009] loss=0.7742
2026-02-13 10:04:35,639 | INFO | FT 6 [8501/10009] loss=0.7735
2026-02-13 10:06:27,916 | INFO | FT 6 [9001/10009] loss=0.7724
2026-02-13 10:08:20,076 | INFO | FT 6 [9501/10009] loss=0.7720
2026-02-13 10:10:12,145 | INFO | FT 6 [10001/10009] loss=0.7714
2026-02-13 10:10:13,948 | INFO | FT 6 [10009/10009] loss=0.7714
2026-02-13 10:11:22,713 | INFO | FT ep 6/10: train_loss=0.7714, val_acc=0.7873
2026-02-13 10:11:22,904 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.9/vbp_best.pth
2026-02-13 10:11:23,949 | INFO | FT 7 [1/10009] loss=0.8593
2026-02-13 10:13:15,154 | INFO | FT 7 [501/10009] loss=0.7378
2026-02-13 10:15:06,988 | INFO | FT 7 [1001/10009] loss=0.7414
2026-02-13 10:16:58,965 | INFO | FT 7 [1501/10009] loss=0.7395
2026-02-13 10:18:51,058 | INFO | FT 7 [2001/10009] loss=0.7386
2026-02-13 10:20:42,568 | INFO | FT 7 [2501/10009] loss=0.7398
2026-02-13 10:22:34,373 | INFO | FT 7 [3001/10009] loss=0.7403
2026-02-13 10:24:25,830 | INFO | FT 7 [3501/10009] loss=0.7394
2026-02-13 10:26:17,307 | INFO | FT 7 [4001/10009] loss=0.7410
2026-02-13 10:28:08,845 | INFO | FT 7 [4501/10009] loss=0.7402
2026-02-13 10:30:00,436 | INFO | FT 7 [5001/10009] loss=0.7403
2026-02-13 10:31:52,289 | INFO | FT 7 [5501/10009] loss=0.7401
2026-02-13 10:33:43,925 | INFO | FT 7 [6001/10009] loss=0.7405
2026-02-13 10:35:35,739 | INFO | FT 7 [6501/10009] loss=0.7404
2026-02-13 10:37:27,644 | INFO | FT 7 [7001/10009] loss=0.7400
2026-02-13 10:39:19,497 | INFO | FT 7 [7501/10009] loss=0.7393
2026-02-13 10:41:11,366 | INFO | FT 7 [8001/10009] loss=0.7396
2026-02-13 10:43:03,217 | INFO | FT 7 [8501/10009] loss=0.7390
2026-02-13 10:44:55,130 | INFO | FT 7 [9001/10009] loss=0.7387
2026-02-13 10:46:47,082 | INFO | FT 7 [9501/10009] loss=0.7388
2026-02-13 10:48:38,392 | INFO | FT 7 [10001/10009] loss=0.7384
2026-02-13 10:48:40,227 | INFO | FT 7 [10009/10009] loss=0.7384
2026-02-13 10:49:46,945 | INFO | FT ep 7/10: train_loss=0.7384, val_acc=0.7887
2026-02-13 10:49:47,147 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.9/vbp_best.pth
2026-02-13 10:49:48,153 | INFO | FT 8 [1/10009] loss=0.8125
2026-02-13 10:51:39,917 | INFO | FT 8 [501/10009] loss=0.7181
2026-02-13 10:53:31,411 | INFO | FT 8 [1001/10009] loss=0.7180
2026-02-13 10:55:23,235 | INFO | FT 8 [1501/10009] loss=0.7221
2026-02-13 10:57:14,331 | INFO | FT 8 [2001/10009] loss=0.7212
2026-02-13 10:59:05,797 | INFO | FT 8 [2501/10009] loss=0.7225
2026-02-13 11:00:57,513 | INFO | FT 8 [3001/10009] loss=0.7214
2026-02-13 11:02:49,600 | INFO | FT 8 [3501/10009] loss=0.7215
2026-02-13 11:04:41,770 | INFO | FT 8 [4001/10009] loss=0.7205
2026-02-13 11:06:33,670 | INFO | FT 8 [4501/10009] loss=0.7197
2026-02-13 11:08:25,873 | INFO | FT 8 [5001/10009] loss=0.7190
2026-02-13 11:10:17,570 | INFO | FT 8 [5501/10009] loss=0.7192
2026-02-13 11:12:09,489 | INFO | FT 8 [6001/10009] loss=0.7186
2026-02-13 11:14:01,310 | INFO | FT 8 [6501/10009] loss=0.7175
2026-02-13 11:15:53,546 | INFO | FT 8 [7001/10009] loss=0.7168
2026-02-13 11:17:45,352 | INFO | FT 8 [7501/10009] loss=0.7162
2026-02-13 11:19:37,303 | INFO | FT 8 [8001/10009] loss=0.7163
2026-02-13 11:21:29,392 | INFO | FT 8 [8501/10009] loss=0.7162
2026-02-13 11:23:21,067 | INFO | FT 8 [9001/10009] loss=0.7154
2026-02-13 11:25:12,548 | INFO | FT 8 [9501/10009] loss=0.7153
2026-02-13 11:27:04,588 | INFO | FT 8 [10001/10009] loss=0.7151
2026-02-13 11:27:06,404 | INFO | FT 8 [10009/10009] loss=0.7151
2026-02-13 11:28:13,633 | INFO | FT ep 8/10: train_loss=0.7151, val_acc=0.7923
2026-02-13 11:28:13,830 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.9/vbp_best.pth
2026-02-13 11:28:14,862 | INFO | FT 9 [1/10009] loss=0.9037
2026-02-13 11:30:07,148 | INFO | FT 9 [501/10009] loss=0.6930
2026-02-13 11:31:58,633 | INFO | FT 9 [1001/10009] loss=0.6925
2026-02-13 11:33:50,611 | INFO | FT 9 [1501/10009] loss=0.6942
2026-02-13 11:35:42,645 | INFO | FT 9 [2001/10009] loss=0.6945
2026-02-13 11:37:35,040 | INFO | FT 9 [2501/10009] loss=0.6949
2026-02-13 11:39:27,142 | INFO | FT 9 [3001/10009] loss=0.6954
2026-02-13 11:41:19,346 | INFO | FT 9 [3501/10009] loss=0.6962
2026-02-13 11:43:11,524 | INFO | FT 9 [4001/10009] loss=0.6963
2026-02-13 11:45:03,464 | INFO | FT 9 [4501/10009] loss=0.6965
2026-02-13 11:46:55,598 | INFO | FT 9 [5001/10009] loss=0.6964
2026-02-13 11:48:47,935 | INFO | FT 9 [5501/10009] loss=0.6959
2026-02-13 11:50:39,972 | INFO | FT 9 [6001/10009] loss=0.6955
2026-02-13 11:52:32,182 | INFO | FT 9 [6501/10009] loss=0.6950
2026-02-13 11:54:24,329 | INFO | FT 9 [7001/10009] loss=0.6954
2026-02-13 11:56:17,004 | INFO | FT 9 [7501/10009] loss=0.6955
2026-02-13 11:58:09,008 | INFO | FT 9 [8001/10009] loss=0.6955
2026-02-13 12:00:00,270 | INFO | FT 9 [8501/10009] loss=0.6947
2026-02-13 12:01:52,205 | INFO | FT 9 [9001/10009] loss=0.6946
2026-02-13 12:03:44,375 | INFO | FT 9 [9501/10009] loss=0.6943
2026-02-13 12:05:36,618 | INFO | FT 9 [10001/10009] loss=0.6944
2026-02-13 12:05:38,457 | INFO | FT 9 [10009/10009] loss=0.6943
2026-02-13 12:06:44,586 | INFO | FT ep 9/10: train_loss=0.6943, val_acc=0.7939
2026-02-13 12:06:44,780 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.9/vbp_best.pth
2026-02-13 12:06:45,725 | INFO | FT 10 [1/10009] loss=0.6904
2026-02-13 12:08:37,586 | INFO | FT 10 [501/10009] loss=0.6888
2026-02-13 12:10:29,361 | INFO | FT 10 [1001/10009] loss=0.6839
2026-02-13 12:12:21,333 | INFO | FT 10 [1501/10009] loss=0.6869
2026-02-13 12:14:13,601 | INFO | FT 10 [2001/10009] loss=0.6843
2026-02-13 12:16:05,654 | INFO | FT 10 [2501/10009] loss=0.6861
2026-02-13 12:17:57,926 | INFO | FT 10 [3001/10009] loss=0.6859
2026-02-13 12:19:50,155 | INFO | FT 10 [3501/10009] loss=0.6856
2026-02-13 12:21:42,292 | INFO | FT 10 [4001/10009] loss=0.6857
2026-02-13 12:23:34,564 | INFO | FT 10 [4501/10009] loss=0.6859
2026-02-13 12:25:26,911 | INFO | FT 10 [5001/10009] loss=0.6864
2026-02-13 12:27:19,226 | INFO | FT 10 [5501/10009] loss=0.6862
2026-02-13 12:29:11,821 | INFO | FT 10 [6001/10009] loss=0.6864
2026-02-13 12:31:03,999 | INFO | FT 10 [6501/10009] loss=0.6863
2026-02-13 12:32:56,377 | INFO | FT 10 [7001/10009] loss=0.6867
2026-02-13 12:34:48,302 | INFO | FT 10 [7501/10009] loss=0.6867
2026-02-13 12:36:40,394 | INFO | FT 10 [8001/10009] loss=0.6870
2026-02-13 12:38:32,814 | INFO | FT 10 [8501/10009] loss=0.6874
