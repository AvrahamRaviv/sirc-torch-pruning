2026-02-13 08:31:52,681 | INFO | Logging to /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.7/vbp_imagenet.log
2026-02-13 08:31:52,681 | INFO | ============================================================
2026-02-13 08:31:52,681 | INFO | VBP ImageNet Reproduction Script
2026-02-13 08:31:52,681 | INFO | ============================================================
2026-02-13 08:31:52,681 | INFO |   model_type: cnn
2026-02-13 08:31:52,681 | INFO |   model_name: /algo/NetOptimization/outputs/VBP/ResNet50_TP/resnet50_imagenet1k.pth
2026-02-13 08:31:52,681 | INFO |   cnn_arch: resnet50
2026-02-13 08:31:52,681 | INFO |   pretrained: True
2026-02-13 08:31:52,681 | INFO |   interior_only: True
2026-02-13 08:31:52,681 | INFO |   data_path: /algo/NetOptimization/outputs/VBP/
2026-02-13 08:31:52,681 | INFO |   train_batch_size: 64
2026-02-13 08:31:52,682 | INFO |   val_batch_size: 128
2026-02-13 08:31:52,682 | INFO |   num_workers: 4
2026-02-13 08:31:52,682 | INFO |   max_batches: 200
2026-02-13 08:31:52,682 | INFO |   keep_ratio: 0.7
2026-02-13 08:31:52,682 | INFO |   global_pruning: True
2026-02-13 08:31:52,682 | INFO |   max_pruning_ratio: 1.0
2026-02-13 08:31:52,682 | INFO |   norm_per_layer: False
2026-02-13 08:31:52,682 | INFO |   no_compensation: False
2026-02-13 08:31:52,682 | INFO |   no_recalib: False
2026-02-13 08:31:52,682 | INFO |   criterion: variance
2026-02-13 08:31:52,682 | INFO |   epochs_ft: 10
2026-02-13 08:31:52,682 | INFO |   lr_ft: 0.0001
2026-02-13 08:31:52,682 | INFO |   opt_ft: adamw
2026-02-13 08:31:52,682 | INFO |   momentum_ft: 0.9
2026-02-13 08:31:52,682 | INFO |   wd_ft: None
2026-02-13 08:31:52,682 | INFO |   use_kd: True
2026-02-13 08:31:52,682 | INFO |   kd_alpha: 0.7
2026-02-13 08:31:52,682 | INFO |   kd_T: 2.0
2026-02-13 08:31:52,682 | INFO |   pat: False
2026-02-13 08:31:52,682 | INFO |   pat_steps: 5
2026-02-13 08:31:52,682 | INFO |   pat_epochs_per_step: 3
2026-02-13 08:31:52,682 | INFO |   var_loss_weight: 0.0
2026-02-13 08:31:52,682 | INFO |   sparse_mode: none
2026-02-13 08:31:52,682 | INFO |   epochs_sparse: 5
2026-02-13 08:31:52,682 | INFO |   lr_sparse: 0.0001
2026-02-13 08:31:52,682 | INFO |   l1_lambda: 0.0001
2026-02-13 08:31:52,682 | INFO |   gmp_target_sparsity: 0.5
2026-02-13 08:31:52,683 | INFO |   disable_ddp: False
2026-02-13 08:31:52,683 | INFO |   local_rank: 0
2026-02-13 08:31:52,683 | INFO |   save_dir: /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.7
2026-02-13 08:31:52,683 | INFO |   rank: 0
2026-02-13 08:31:52,683 | INFO |   world_size: 2
2026-02-13 08:31:52,683 | INFO | Loading ImageNet dataset...
2026-02-13 08:31:52,683 | INFO | Using cached sample lists for fast loading
2026-02-13 08:31:53,058 | INFO | Train samples: 1281167, Val samples: 50000
2026-02-13 08:31:55,237 | INFO | Loaded resnet50 (pretrained=True)
2026-02-13 08:31:56,722 | INFO | Baseline: 4.12G MACs, 25.56M params
2026-02-13 08:31:56,723 | INFO | Evaluating original model...
2026-02-13 08:33:03,570 | INFO | Original accuracy: 0.8035, loss: 1.4124
2026-02-13 08:33:03,594 | INFO | Created teacher model for knowledge distillation
2026-02-13 08:33:03,594 | INFO | PAT: 1 steps, per_step_keep=0.7000, epochs_per_step=0, target_keep=0.7, criterion=variance
2026-02-13 08:33:03,595 | INFO | 
============================================================
2026-02-13 08:33:03,595 | INFO | PAT Step 1/1
2026-02-13 08:33:03,595 | INFO | ============================================================
2026-02-13 08:33:03,622 | INFO | Auto-detected 53 CNN target layers for stats
2026-02-13 08:33:03,622 | INFO | Collecting activation variance statistics...
2026-02-13 08:33:23,878 | INFO | Statistics collected for 53 layers
2026-02-13 08:33:23,879 | INFO |   Conv2d: mean_var=5.515879
2026-02-13 08:33:23,879 | INFO |   Conv2d: mean_var=1.090728
2026-02-13 08:33:23,879 | INFO |   Conv2d: mean_var=2.072395
2026-02-13 08:33:23,879 | INFO |   Conv2d: mean_var=13.779720
2026-02-13 08:33:23,879 | INFO |   Conv2d: mean_var=16.711683
2026-02-13 08:33:24,036 | INFO | Variance â€” entropy=0.9314, cv=1.5011, gini=0.6155
2026-02-13 08:33:24,082 | INFO | Pruning: per_step_prune=0.3000
2026-02-13 08:33:24,579 | INFO | Pruning complete (criterion=VBP, compensation=on)
2026-02-13 08:33:24,579 | INFO | Recalibrating BN running stats...
2026-02-13 08:33:25,418 | INFO | BN recalib [1/100]
2026-02-13 08:33:25,598 | INFO | BN recalib [6/100]
2026-02-13 08:33:25,888 | INFO | BN recalib [11/100]
2026-02-13 08:33:26,271 | INFO | BN recalib [16/100]
2026-02-13 08:33:27,054 | INFO | BN recalib [21/100]
2026-02-13 08:33:27,357 | INFO | BN recalib [26/100]
2026-02-13 08:33:27,728 | INFO | BN recalib [31/100]
2026-02-13 08:33:28,046 | INFO | BN recalib [36/100]
2026-02-13 08:33:28,659 | INFO | BN recalib [41/100]
2026-02-13 08:33:28,951 | INFO | BN recalib [46/100]
2026-02-13 08:33:29,264 | INFO | BN recalib [51/100]
2026-02-13 08:33:29,578 | INFO | BN recalib [56/100]
2026-02-13 08:33:30,121 | INFO | BN recalib [61/100]
2026-02-13 08:33:30,420 | INFO | BN recalib [66/100]
2026-02-13 08:33:30,725 | INFO | BN recalib [71/100]
2026-02-13 08:33:31,033 | INFO | BN recalib [76/100]
2026-02-13 08:33:31,585 | INFO | BN recalib [81/100]
2026-02-13 08:33:31,871 | INFO | BN recalib [86/100]
2026-02-13 08:33:32,188 | INFO | BN recalib [91/100]
2026-02-13 08:33:32,481 | INFO | BN recalib [96/100]
2026-02-13 08:33:32,844 | INFO | BN recalib [100/100]
2026-02-13 08:33:33,414 | INFO | BN recalibration done (100 batches)
2026-02-13 08:34:36,104 | INFO | Step 1 retention: acc=0.6577, loss=3.0420
2026-02-13 08:34:36,105 | INFO |   cumulative_keep=0.7000, MACs=3.17G, params=15.90M
2026-02-13 08:34:36,105 | INFO | 
Post-prune fine-tuning for 10 epochs (adamw, lr=0.0001, wd=0.01)...
2026-02-13 08:34:37,180 | INFO | FT 1 [1/10009] loss=2.3332
2026-02-13 08:36:20,664 | INFO | FT 1 [501/10009] loss=1.2966
2026-02-13 08:38:04,629 | INFO | FT 1 [1001/10009] loss=1.2388
2026-02-13 08:39:48,151 | INFO | FT 1 [1501/10009] loss=1.2085
2026-02-13 08:41:31,930 | INFO | FT 1 [2001/10009] loss=1.1888
2026-02-13 08:43:15,685 | INFO | FT 1 [2501/10009] loss=1.1766
2026-02-13 08:44:59,149 | INFO | FT 1 [3001/10009] loss=1.1658
2026-02-13 08:46:42,895 | INFO | FT 1 [3501/10009] loss=1.1577
2026-02-13 08:48:26,576 | INFO | FT 1 [4001/10009] loss=1.1499
2026-02-13 08:50:10,342 | INFO | FT 1 [4501/10009] loss=1.1451
2026-02-13 08:51:53,971 | INFO | FT 1 [5001/10009] loss=1.1405
2026-02-13 08:53:37,664 | INFO | FT 1 [5501/10009] loss=1.1348
2026-02-13 08:55:21,511 | INFO | FT 1 [6001/10009] loss=1.1315
2026-02-13 08:57:05,099 | INFO | FT 1 [6501/10009] loss=1.1268
2026-02-13 08:58:48,699 | INFO | FT 1 [7001/10009] loss=1.1236
2026-02-13 09:00:32,191 | INFO | FT 1 [7501/10009] loss=1.1199
2026-02-13 09:02:15,727 | INFO | FT 1 [8001/10009] loss=1.1172
2026-02-13 09:03:59,564 | INFO | FT 1 [8501/10009] loss=1.1148
2026-02-13 09:05:43,034 | INFO | FT 1 [9001/10009] loss=1.1125
2026-02-13 09:07:26,306 | INFO | FT 1 [9501/10009] loss=1.1101
2026-02-13 09:09:09,682 | INFO | FT 1 [10001/10009] loss=1.1080
2026-02-13 09:09:11,343 | INFO | FT 1 [10009/10009] loss=1.1080
2026-02-13 09:10:19,521 | INFO | FT ep 1/10: train_loss=1.1080, val_acc=0.7517
2026-02-13 09:10:19,675 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.7/vbp_best.pth
2026-02-13 09:10:20,625 | INFO | FT 2 [1/10009] loss=0.9397
2026-02-13 09:12:04,001 | INFO | FT 2 [501/10009] loss=1.0140
2026-02-13 09:13:47,930 | INFO | FT 2 [1001/10009] loss=1.0207
2026-02-13 09:15:31,899 | INFO | FT 2 [1501/10009] loss=1.0241
2026-02-13 09:17:16,140 | INFO | FT 2 [2001/10009] loss=1.0238
2026-02-13 09:18:59,845 | INFO | FT 2 [2501/10009] loss=1.0243
2026-02-13 09:20:43,704 | INFO | FT 2 [3001/10009] loss=1.0231
2026-02-13 09:22:27,535 | INFO | FT 2 [3501/10009] loss=1.0239
2026-02-13 09:24:11,828 | INFO | FT 2 [4001/10009] loss=1.0253
2026-02-13 09:25:55,823 | INFO | FT 2 [4501/10009] loss=1.0264
2026-02-13 09:27:39,749 | INFO | FT 2 [5001/10009] loss=1.0258
2026-02-13 09:29:23,697 | INFO | FT 2 [5501/10009] loss=1.0257
2026-02-13 09:31:07,462 | INFO | FT 2 [6001/10009] loss=1.0255
2026-02-13 09:32:51,813 | INFO | FT 2 [6501/10009] loss=1.0255
2026-02-13 09:34:35,734 | INFO | FT 2 [7001/10009] loss=1.0260
2026-02-13 09:36:19,688 | INFO | FT 2 [7501/10009] loss=1.0256
2026-02-13 09:38:03,285 | INFO | FT 2 [8001/10009] loss=1.0251
2026-02-13 09:39:47,382 | INFO | FT 2 [8501/10009] loss=1.0253
2026-02-13 09:41:31,441 | INFO | FT 2 [9001/10009] loss=1.0250
2026-02-13 09:43:15,314 | INFO | FT 2 [9501/10009] loss=1.0248
2026-02-13 09:44:59,070 | INFO | FT 2 [10001/10009] loss=1.0242
2026-02-13 09:45:00,746 | INFO | FT 2 [10009/10009] loss=1.0241
2026-02-13 09:46:07,093 | INFO | FT ep 2/10: train_loss=1.0241, val_acc=0.7597
2026-02-13 09:46:07,231 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.7/vbp_best.pth
2026-02-13 09:46:08,224 | INFO | FT 3 [1/10009] loss=1.3349
2026-02-13 09:47:51,437 | INFO | FT 3 [501/10009] loss=0.9686
2026-02-13 09:49:34,912 | INFO | FT 3 [1001/10009] loss=0.9704
2026-02-13 09:51:18,421 | INFO | FT 3 [1501/10009] loss=0.9744
2026-02-13 09:53:01,901 | INFO | FT 3 [2001/10009] loss=0.9773
2026-02-13 09:54:45,510 | INFO | FT 3 [2501/10009] loss=0.9775
2026-02-13 09:56:29,141 | INFO | FT 3 [3001/10009] loss=0.9780
2026-02-13 09:58:12,710 | INFO | FT 3 [3501/10009] loss=0.9787
2026-02-13 09:59:56,333 | INFO | FT 3 [4001/10009] loss=0.9790
2026-02-13 10:01:39,784 | INFO | FT 3 [4501/10009] loss=0.9803
2026-02-13 10:03:23,367 | INFO | FT 3 [5001/10009] loss=0.9829
2026-02-13 10:05:06,751 | INFO | FT 3 [5501/10009] loss=0.9829
2026-02-13 10:06:50,198 | INFO | FT 3 [6001/10009] loss=0.9828
2026-02-13 10:08:33,713 | INFO | FT 3 [6501/10009] loss=0.9839
2026-02-13 10:10:17,079 | INFO | FT 3 [7001/10009] loss=0.9837
2026-02-13 10:12:00,681 | INFO | FT 3 [7501/10009] loss=0.9841
2026-02-13 10:13:43,974 | INFO | FT 3 [8001/10009] loss=0.9840
2026-02-13 10:15:27,552 | INFO | FT 3 [8501/10009] loss=0.9840
2026-02-13 10:17:11,091 | INFO | FT 3 [9001/10009] loss=0.9832
2026-02-13 10:18:54,599 | INFO | FT 3 [9501/10009] loss=0.9833
2026-02-13 10:20:37,797 | INFO | FT 3 [10001/10009] loss=0.9833
2026-02-13 10:20:39,468 | INFO | FT 3 [10009/10009] loss=0.9833
2026-02-13 10:21:47,226 | INFO | FT ep 3/10: train_loss=0.9833, val_acc=0.7637
2026-02-13 10:21:47,369 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.7/vbp_best.pth
2026-02-13 10:21:48,325 | INFO | FT 4 [1/10009] loss=0.7802
2026-02-13 10:23:31,901 | INFO | FT 4 [501/10009] loss=0.9351
2026-02-13 10:25:15,541 | INFO | FT 4 [1001/10009] loss=0.9377
2026-02-13 10:26:59,176 | INFO | FT 4 [1501/10009] loss=0.9380
2026-02-13 10:28:42,752 | INFO | FT 4 [2001/10009] loss=0.9375
2026-02-13 10:30:26,587 | INFO | FT 4 [2501/10009] loss=0.9386
2026-02-13 10:32:09,983 | INFO | FT 4 [3001/10009] loss=0.9408
2026-02-13 10:33:53,633 | INFO | FT 4 [3501/10009] loss=0.9421
2026-02-13 10:35:37,341 | INFO | FT 4 [4001/10009] loss=0.9427
2026-02-13 10:37:20,989 | INFO | FT 4 [4501/10009] loss=0.9426
2026-02-13 10:39:04,675 | INFO | FT 4 [5001/10009] loss=0.9436
2026-02-13 10:40:48,191 | INFO | FT 4 [5501/10009] loss=0.9447
2026-02-13 10:42:32,071 | INFO | FT 4 [6001/10009] loss=0.9454
2026-02-13 10:44:16,022 | INFO | FT 4 [6501/10009] loss=0.9461
2026-02-13 10:45:59,769 | INFO | FT 4 [7001/10009] loss=0.9458
2026-02-13 10:47:43,268 | INFO | FT 4 [7501/10009] loss=0.9457
2026-02-13 10:49:27,091 | INFO | FT 4 [8001/10009] loss=0.9448
2026-02-13 10:51:11,303 | INFO | FT 4 [8501/10009] loss=0.9442
2026-02-13 10:52:55,081 | INFO | FT 4 [9001/10009] loss=0.9444
2026-02-13 10:54:38,715 | INFO | FT 4 [9501/10009] loss=0.9444
2026-02-13 10:56:22,049 | INFO | FT 4 [10001/10009] loss=0.9441
2026-02-13 10:56:23,708 | INFO | FT 4 [10009/10009] loss=0.9441
2026-02-13 10:57:27,132 | INFO | FT ep 4/10: train_loss=0.9441, val_acc=0.7690
2026-02-13 10:57:27,316 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.7/vbp_best.pth
2026-02-13 10:57:28,333 | INFO | FT 5 [1/10009] loss=1.1713
2026-02-13 10:59:11,826 | INFO | FT 5 [501/10009] loss=0.9045
2026-02-13 11:00:55,164 | INFO | FT 5 [1001/10009] loss=0.9067
2026-02-13 11:02:38,781 | INFO | FT 5 [1501/10009] loss=0.9044
2026-02-13 11:04:22,446 | INFO | FT 5 [2001/10009] loss=0.9069
2026-02-13 11:06:06,172 | INFO | FT 5 [2501/10009] loss=0.9081
2026-02-13 11:07:49,722 | INFO | FT 5 [3001/10009] loss=0.9079
2026-02-13 11:09:33,513 | INFO | FT 5 [3501/10009] loss=0.9068
2026-02-13 11:11:17,207 | INFO | FT 5 [4001/10009] loss=0.9084
2026-02-13 11:13:00,886 | INFO | FT 5 [4501/10009] loss=0.9087
2026-02-13 11:14:44,632 | INFO | FT 5 [5001/10009] loss=0.9090
2026-02-13 11:16:28,302 | INFO | FT 5 [5501/10009] loss=0.9085
2026-02-13 11:18:11,795 | INFO | FT 5 [6001/10009] loss=0.9088
2026-02-13 11:19:55,124 | INFO | FT 5 [6501/10009] loss=0.9091
2026-02-13 11:21:38,779 | INFO | FT 5 [7001/10009] loss=0.9088
2026-02-13 11:23:22,275 | INFO | FT 5 [7501/10009] loss=0.9089
2026-02-13 11:25:05,777 | INFO | FT 5 [8001/10009] loss=0.9087
2026-02-13 11:26:49,461 | INFO | FT 5 [8501/10009] loss=0.9085
2026-02-13 11:28:33,609 | INFO | FT 5 [9001/10009] loss=0.9081
2026-02-13 11:30:17,400 | INFO | FT 5 [9501/10009] loss=0.9084
2026-02-13 11:32:01,173 | INFO | FT 5 [10001/10009] loss=0.9079
2026-02-13 11:32:02,848 | INFO | FT 5 [10009/10009] loss=0.9078
2026-02-13 11:33:07,955 | INFO | FT ep 5/10: train_loss=0.9078, val_acc=0.7747
2026-02-13 11:33:08,120 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.7/vbp_best.pth
2026-02-13 11:33:09,141 | INFO | FT 6 [1/10009] loss=0.8911
2026-02-13 11:34:52,254 | INFO | FT 6 [501/10009] loss=0.8737
2026-02-13 11:36:35,641 | INFO | FT 6 [1001/10009] loss=0.8766
2026-02-13 11:38:19,212 | INFO | FT 6 [1501/10009] loss=0.8798
2026-02-13 11:40:02,820 | INFO | FT 6 [2001/10009] loss=0.8793
2026-02-13 11:41:46,207 | INFO | FT 6 [2501/10009] loss=0.8785
2026-02-13 11:43:29,800 | INFO | FT 6 [3001/10009] loss=0.8772
2026-02-13 11:45:13,285 | INFO | FT 6 [3501/10009] loss=0.8772
2026-02-13 11:46:57,026 | INFO | FT 6 [4001/10009] loss=0.8772
2026-02-13 11:48:40,510 | INFO | FT 6 [4501/10009] loss=0.8779
2026-02-13 11:50:23,542 | INFO | FT 6 [5001/10009] loss=0.8780
2026-02-13 11:52:07,349 | INFO | FT 6 [5501/10009] loss=0.8782
2026-02-13 11:53:50,964 | INFO | FT 6 [6001/10009] loss=0.8771
2026-02-13 11:55:34,676 | INFO | FT 6 [6501/10009] loss=0.8769
2026-02-13 11:57:18,168 | INFO | FT 6 [7001/10009] loss=0.8773
2026-02-13 11:59:01,434 | INFO | FT 6 [7501/10009] loss=0.8769
2026-02-13 12:00:44,990 | INFO | FT 6 [8001/10009] loss=0.8769
2026-02-13 12:02:28,478 | INFO | FT 6 [8501/10009] loss=0.8759
2026-02-13 12:04:12,293 | INFO | FT 6 [9001/10009] loss=0.8750
2026-02-13 12:05:55,512 | INFO | FT 6 [9501/10009] loss=0.8739
2026-02-13 12:07:39,508 | INFO | FT 6 [10001/10009] loss=0.8738
2026-02-13 12:07:41,175 | INFO | FT 6 [10009/10009] loss=0.8738
2026-02-13 12:08:48,151 | INFO | FT ep 6/10: train_loss=0.8738, val_acc=0.7764
2026-02-13 12:08:48,298 | INFO | New best! Saved to /algo/NetOptimization/outputs/VBP/ResNet50_TP/global/kr_0.7/vbp_best.pth
2026-02-13 12:08:49,265 | INFO | FT 7 [1/10009] loss=1.0444
2026-02-13 12:10:32,688 | INFO | FT 7 [501/10009] loss=0.8467
2026-02-13 12:12:16,345 | INFO | FT 7 [1001/10009] loss=0.8414
2026-02-13 12:14:00,608 | INFO | FT 7 [1501/10009] loss=0.8410
2026-02-13 12:15:44,252 | INFO | FT 7 [2001/10009] loss=0.8407
2026-02-13 12:17:27,815 | INFO | FT 7 [2501/10009] loss=0.8399
2026-02-13 12:19:11,393 | INFO | FT 7 [3001/10009] loss=0.8407
2026-02-13 12:20:54,763 | INFO | FT 7 [3501/10009] loss=0.8406
2026-02-13 12:22:38,531 | INFO | FT 7 [4001/10009] loss=0.8426
2026-02-13 12:24:22,105 | INFO | FT 7 [4501/10009] loss=0.8413
2026-02-13 12:26:05,574 | INFO | FT 7 [5001/10009] loss=0.8411
2026-02-13 12:27:49,103 | INFO | FT 7 [5501/10009] loss=0.8406
2026-02-13 12:29:32,851 | INFO | FT 7 [6001/10009] loss=0.8416
2026-02-13 12:31:16,200 | INFO | FT 7 [6501/10009] loss=0.8418
2026-02-13 12:32:59,540 | INFO | FT 7 [7001/10009] loss=0.8413
2026-02-13 12:34:43,113 | INFO | FT 7 [7501/10009] loss=0.8411
2026-02-13 12:36:26,965 | INFO | FT 7 [8001/10009] loss=0.8414
2026-02-13 12:38:10,592 | INFO | FT 7 [8501/10009] loss=0.8410
2026-02-13 12:39:54,062 | INFO | FT 7 [9001/10009] loss=0.8409
